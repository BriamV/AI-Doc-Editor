# Desglose Detallado y Enriquecido de Tareas (WBS Nivel 4)

Esta secci√≥n proporciona el desglose completo, auditable y enriquecido de cada Tarea (GTI) en Subtareas (ST) at√≥micas. Cada tarea se presenta como una ficha de trabajo completa, seguida de su descomposici√≥n en subtareas, asegurando la m√°xima claridad y trazabilidad.

---

### **Tarea T-01: Baseline & CI/CD**

- **ID de Tarea:** T-01

- **T√≠tulo:** Baseline & CI/CD
- **Estado:** Completado 83% (Pydantic v2 diferido a R1 por ADR-004)
- **Dependencias:** Ninguna
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Establecer la infraestructura de c√≥digo, el entorno de desarrollo local y el pipeline de Integraci√≥n Continua (CI) que servir√° como base para todo el proyecto. Esta tarea es fundamental para garantizar la calidad, consistencia y automatizaci√≥n desde el primer d√≠a. **El alcance incluye la migraci√≥n del backend a Pydantic v2 y el freeze de dependencias de producci√≥n para aprovechar sus mejoras de rendimiento.**
- **Detalles T√©cnicos:**
  - **Stack:** Docker, Docker Compose, Makefile, GitHub Actions.
  - **Librer√≠as Clave:** Migraci√≥n a Pydantic v2.
  - **Linters:** ruff, black (Python), eslint (TypeScript/JS).
  - **An√°lisis de Calidad:** radon (complejidad ciclom√°tica), SonarJS o similar.
  - **Gobernanza:** CODEOWNERS, plantillas de PR y ADR.
- **Estrategia de Test:**
  - **Unit Tests:** El pipeline debe ejecutar los tests unitarios de backend y frontend. Cobertura inicial > 80%.
  - **Integration Tests:** El pipeline debe ser capaz de construir las im√°genes de Docker y ejecutar un test de humo.
  - **Performance Tests:** Un benchmark debe validar la mejora de rendimiento tras la migraci√≥n a Pydantic v2.
- **Documentaci√≥n:**
  - Crear CONTRIBUTING.md con instrucciones de setup.
  - Crear la primera entrada en /docs/adr/000-initial-architecture-decision.md.
- **Criterios de Aceptaci√≥n:**
  - El pipeline se ejecuta y pasa (verde) en el commit inicial del monorepo.
  - El fichero ADR-000 est√° registrado y versionado.
  - El job qa-gate integra an√°lisis est√°tico (radon, SonarJS) y falla si se superan umbrales cr√≠ticos de complejidad.
  - El pipeline valida que los t√≠tulos de los Pull Requests sigan la convenci√≥n feat(T-XX): ....
  - La migraci√≥n a Pydantic v2 est√° completada y un benchmark demuestra una mejora de rendimiento significativa.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests del pipeline inicial pasan.
  - Documentaci√≥n (CONTRIBUTING.md, ADR-000) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                              | Complejidad Estimada | Entregable Verificable                                                                                                                 |
| :------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------- | :------------------------------------------------------------------------------------------------------------------------------------- |
| R0.WP1-T01-ST1                   | Configurar estructura de monorepo, `docker-compose.yml` para servicios base (backend, frontend, db) y `Makefile` con comandos comunes (up, down, test). | 3                    | `make up` levanta el entorno local. Repositorio inicializado con la estructura de directorios definida.                                |
| R0.WP1-T01-ST2                   | Crear pipeline de CI en GitHub Actions que instala dependencias, ejecuta linters (ruff, eslint) y tests unitarios en cada PR.                           | 3                    | PR a `main` dispara el pipeline y este pasa o falla seg√∫n la calidad del c√≥digo. Logs de CI disponibles.                               |
| R0.WP1-T01-ST3                   | Implementar el job `qa-gate` con an√°lisis de complejidad (radon), linter de t√≠tulos de PR, `CODEOWNERS` y plantilla de ADR.                             | 4                    | Un PR con un t√≠tulo no convencional o c√≥digo que excede el umbral de complejidad es bloqueado por el pipeline. Fichero ADR-000 existe. |
| R0.WP1-T01-ST4                   | Migrar los modelos de datos del backend a Pydantic v2 y realizar un benchmark para validar la mejora de rendimiento.                                    | 2                    | Pull Request con la migraci√≥n completada. Reporte de benchmark que muestra la mejora de rendimiento.                                   |

---

### **Tarea T-02: OAuth 2.0 + JWT Roles**

- **ID de Tarea:** T-02
- **T√≠tulo:** OAuth 2.0 + JWT Roles
- **Estado:** üöß Desarrollo Completado - Listo para QA
- **Dependencias:** T-01
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Implementar el sistema de autenticaci√≥n y autorizaci√≥n. Los usuarios se autenticar√°n mediante proveedores externos (Google/Microsoft) usando OAuth 2.0, y el sistema gestionar√° su acceso a trav√©s de roles (editor, admin) embebidos en JSON Web Tokens (JWT).
- **Detalles T√©cnicos:**
  - **Protocolos:** OAuth 2.0 (Authorization Code Flow), JWT (RS256).
  - **Backend:** Python (FastAPI), python-jose para JWT.
  - **Endpoints:** /auth/login, /auth/callback, /auth/refresh, /users/me.
- **Estrategia de Test:**
  - **Unit Tests:** Cubrir la l√≥gica de creaci√≥n y validaci√≥n de JWT.
  - **Integration Tests:** Flujo completo de login, obtenci√≥n de token y acceso a un endpoint protegido.
  - **Security Tests:** Verificar la expiraci√≥n de tokens, validaci√≥n de firma, y que un rol editor no puede acceder a endpoints de admin.
- **Documentaci√≥n:**
  - Actualizar la especificaci√≥n OpenAPI con los nuevos endpoints de autenticaci√≥n.
- **Criterios de Aceptaci√≥n:**
  - Un usuario puede completar el flujo de login con Google/MS.
  - El sistema devuelve un JWT v√°lido con el rol correcto tras el login.
  - Un endpoint protegido devuelve 401/403 si el token es inv√°lido, ha expirado o no tiene el rol requerido.
  - El endpoint /auth/refresh funciona correctamente.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration, security) pasan.
  - Documentaci√≥n de API completada.
  - Integraci√≥n con el sistema de usuarios verificada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                                                                     |                      |                                                                                                                        |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                          | Complejidad Estimada | Entregable Verificable                                                                                                 |
| R0.WP2-T02-ST1                   | Implementar el flujo de autenticaci√≥n OAuth 2.0 (servidor) para Google y Microsoft, incluyendo callbacks y creaci√≥n/actualizaci√≥n de usuario en DB. | 5                    | Test de integraci√≥n que completa el flujo OAuth y verifica la existencia del usuario en la DB con los datos correctos. |
| R0.WP2-T02-ST2                   | Implementar la generaci√≥n de JWT (access y refresh tokens) con roles (editor, admin) y el endpoint¬†/auth/refresh.                                   | 4                    | Colecci√≥n Postman que demuestra que el login devuelve tokens y que¬†/auth/refresh¬†emite un nuevo access token v√°lido.   |

---

### **Tarea T-03: L√≠mites de Ingesta & Rate**

- **ID de Tarea:** T-03
- **T√≠tulo:** L√≠mites de Ingesta & Rate
- **Estado:** Pendiente
- **Dependencias:** T-44
- **Prioridad:** Alta
- **Release Target:** Release 1
- **Descripci√≥n:** Implementar mecanismos de control para prevenir el abuso y garantizar la estabilidad del sistema. Esto incluye limitar la cantidad de datos que un usuario puede ingestar y la frecuencia de las peticiones a los endpoints m√°s costosos. **Nota de Dependencia Cr√≠tica:** Esta tarea depende del servicio "Config Store" (T-44) para leer y persistir los l√≠mites. La API de T-44 debe ser dise√±ada teniendo en cuenta este requisito.
- **Detalles T√©cnicos:**
  - **Rate Limiting:** Middleware en FastAPI usando un backend de Redis para el conteo.
  - **L√≠mites de Ingesta:** L√≥gica de negocio en el servicio de subida que consulta los l√≠mites configurados por el administrador.
  - **Configuraci√≥n:** Modelo en la DB para almacenar los l√≠mites (N¬∫ docs, MB totales).
- **Estrategia de Test:**
  - **Performance Tests:** Test de carga (JMeter/Locust) para verificar que el rate limiter responde con HTTP 429 cuando se supera el umbral.
  - **Integration Tests:** Test que intenta subir un archivo que excede la cuota y verifica que se recibe un HTTP 400.
- **Documentaci√≥n:**
  - Documentar los c√≥digos de error 429 y 400 en la especificaci√≥n de la API.
- **Criterios de Aceptaci√≥n:**
  - Una carga de N+1 documentos o un tama√±o superior al l√≠mite en MB resulta en una respuesta HTTP 400.
  - Realizar 40 peticiones por minuto a los endpoints rate-limitados resulta en respuestas HTTP 429.
  - Los l√≠mites son configurables mediante la API del Config Store (T-44) y se persisten en la base de datos. La UI para su gesti√≥n por un administrador se completar√° en T-37.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, performance) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 11)**

|                                  |                                                                                                                                                |                      |                                                                                                         |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                     | Complejidad Estimada | Entregable Verificable                                                                                  |
| R1.WP1-T03-ST1                   | Implementar middleware de rate-limiting (con Redis) para los endpoints cr√≠ticos (/upload, /rewrite, /plan, /draft_section).                    | 4                    | Test de carga que supera 30 req/min al endpoint /plan recibe respuestas HTTP 429.                       |
| R1.WP1-T03-ST2                   | Desarrollar la l√≥gica de backend para validar los l√≠mites de ingesta (N¬∫ de documentos, tama√±o total en MB) contra la configuraci√≥n del admin. | 4                    | Test unitario que simula una carga que excede el l√≠mite de MB y recibe un error de validaci√≥n HTTP 400. |
| R1.WP1-T03-ST3                   | Crear la secci√≥n "L√≠mites de Uso" en el panel de admin (usando el esqueleto de T-44) para configurar estos valores y persistirlos en la DB.    | 3                    | Test Cypress donde un admin guarda nuevos l√≠mites y se verifica que se persisten en la DB.              |

---

### **Tarea T-04: File Ingesta RAG + Perf**

- **ID de Tarea:** T-04
- **T√≠tulo:** File Ingesta RAG + Perf
- **Estado:** Pendiente
- **Dependencias:** T-12, T-41
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 1
- **Descripci√≥n:** Desarrollar el pipeline completo de ingesta de documentos para el sistema RAG. Esto implica recibir archivos, extraer su contenido, generar embeddings vectoriales y almacenarlos en una base de datos vectorial para su posterior recuperaci√≥n. El rendimiento es un factor clave.
- **Detalles T√©cnicos:**
  - **Endpoint:** REST API POST /upload (multipart/form-data).
  - **Extracci√≥n:** Librer√≠as como pypdf, python-docx.
  - **Embeddings:** Modelo text-embedding-3-small de OpenAI.
  - **Vector Store:** ChromaDB.
  - **Benchmarking:** JMeter/Locust.

- **Estrategia de Test:**
  - **Unit Tests:** Para los m√≥dulos de extracci√≥n de texto y chunking.
  - **Integration Tests:** Flujo completo desde la subida de un archivo hasta la verificaci√≥n de su existencia en ChromaDB. Test de regresi√≥n para la l√≥gica de upsert.
  - **Performance Tests:** Medir la tasa de ingesta (MB/h) y la latencia de b√∫squeda p95.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el endpoint /upload.
  - ADR sobre la elecci√≥n de ChromaDB y la estrategia de chunking.
  - **Acta de Certificaci√≥n de KPI (seg√∫n plantilla de T-17) firmada por el Tech Lead.**
- **Criterios de Aceptaci√≥n:**
  - Una suite de JMeter evidencia que se cumplen los objetivos de rendimiento (PERF-003, PERF-004).
  - Un test de regresi√≥n verifica que un upsert de un documento existente actualiza los vectores y los antiguos no son recuperables.
  - Los metadatos del documento (nombre, tipo) son visibles en la UI despu√©s de la carga.
  - **Acta de Certificaci√≥n de KPI (seg√∫n plantilla de T-17) firmada por el Tech Lead.**

- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration, performance) pasan.
  - Documentaci√≥n (API, ADR) completada.
  - **Acta de Certificaci√≥n de KPI (seg√∫n plantilla de T-17) firmada por el Tech Lead.**
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 18)**

|                                  |                                                                                                    |                      |                                                                                                               |
| -------------------------------- | -------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                         | Complejidad Estimada | Entregable Verificable                                                                                        |
| R1.WP1-T04-ST1                   | Implementar endpoint REST¬†/upload¬†con validaci√≥n de archivos (MIME type, tama√±o) y metadatos.      | 4                    | Colecci√≥n Postman que prueba subidas v√°lidas (200 OK) e inv√°lidas (400 Bad Request).                          |
| R1.WP1-T04-ST2                   | Desarrollar el m√≥dulo de extracci√≥n de texto para PDF, DOCX y MD, incluyendo el chunking de texto. | 5                    | Tests unitarios que procesan ficheros de ejemplo y devuelven el texto extra√≠do y chunked correctamente.       |
| R1.WP1-T04-ST3                   | Integrar cliente OpenAI para generar embeddings (text-embedding-3-small).                          | 2                    | Test de integraci√≥n que invoca al cliente OpenAI y verifica que se reciben los vectores.                      |
| R1.WP1-T04-ST4                   | Implementar l√≥gica de¬†upsert¬†en ChromaDB para indexar y actualizar vectores y metadatos.           | 3                    | Test de integraci√≥n que sube un documento, genera embeddings y verifica que los vectores existen en ChromaDB. |
| R1.WP1-T04-ST5                   | Crear script de benchmark (JMeter/Locust) para medir rendimiento de ingesta (PERF-003).            | 2                    | Reporte de JMeter/Locust que muestra las m√©tricas de rendimiento de ingesta.                                  |
| R1.WP1-T04-ST6                   | Crear script de benchmark para medir latencia de b√∫squeda vectorial (PERF-004).                    | 2                    | Reporte de JMeter/Locust que muestra las m√©tricas de latencia de b√∫squeda.                                    |

---

### **Tarea T-05: Planner Service (/plan)**

- **ID de Tarea:** T-05
- **T√≠tulo:** Planner Service (/plan)
- **Estado:** Pendiente
- **Dependencias:** T-01, T-41
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 1
- **Descripci√≥n:** Crear el servicio de backend que, a partir de un prompt inicial, genera un esquema estructurado (outline) del documento. Este servicio es el primer paso en el pipeline de generaci√≥n de contenido y debe ser r√°pido y fiable.
- **Detalles T√©cnicos:**
  - **Arquitectura:** Hexagonal (Ports & Adapters) para aislar la l√≥gica de negocio.
  - **Protocolo:** HTTP POST a /plan.
  - **Payload:** JSON con el prompt del usuario.
  - **Respuesta:** JSON con el outline estructurado (H1, H2, H3).
  - **IA:** LLM para la generaci√≥n del outline.
- **Estrategia de Test:**
  - **Unit Tests:** Probar la l√≥gica de validaci√≥n de la respuesta del LLM y el modo fallback.
  - **Integration Tests:** Llamada al endpoint /plan y verificaci√≥n de la estructura del JSON de respuesta.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el endpoint /plan.
  - Diagrama de flujo del proceso de generaci√≥n del plan.
- **Criterios de Aceptaci√≥n:**
  - La petici√≥n al endpoint /plan devuelve una respuesta en ‚â§ 1 segundo.
  - La respuesta es un JSON v√°lido que contiene una estructura de headings H1-H3.
  - El servicio incluye una l√≥gica de fallback a un modo 'single-shot' si el outline generado no cumple un umbral de calidad.
  - Un test E2E demuestra la generaci√≥n de un borrador inicial seg√∫n el flujo documentado.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration) pasan.
  - Documentaci√≥n (API, diagrama) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                                               |                      |                                                                                                                                      |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                    | Complejidad Estimada | Entregable Verificable                                                                                                               |
| R1.WP2-T05-ST1                   | Dise√±ar la arquitectura del servicio (Hexagonal) y definir el contrato de la API para /plan en OpenAPI.                       | 3                    | Documento OpenAPI actualizado y un ADR que justifica la elecci√≥n de la arquitectura.                                                 |
| R1.WP2-T05-ST2                   | Implementar la l√≥gica de "Outline-Guided Thought Generation" que interact√∫a con el LLM para generar el esquema del documento. | 6                    | Test unitario que, dado un prompt, invoca al LLM y valida que la respuesta es un JSON con la estructura de outline esperada (H1-H3). |
| R1.WP2-T05-ST3                   | Implementar la l√≥gica de fallback a modo 'single-shot' y el test E2E que valida el flujo completo.                            | 5                    | Test E2E que simula una respuesta de outline de baja calidad y verifica que el sistema cambia al modo fallback.                      |

---

### **Tarea T-06: Sections WS**

- **ID de Tarea:** T-06
- **T√≠tulo:** Sections WS
- **Estado:** Pendiente
- **Dependencias:** T-05, T-41
- **Prioridad:** Alta
- **Release Target:** Release 1
- **Descripci√≥n:** Implementar el servicio de WebSocket que genera el contenido de cada secci√≥n del documento de forma progresiva (streaming). Esto proporciona al usuario una retroalimentaci√≥n visual inmediata y mejora la experiencia de usuario.
- **Detalles T√©cnicos:**
  - **Protocolo:** WebSocket.
  - **Flujo:** El cliente se conecta, el servidor toma el plan de T-05 y comienza a generar y emitir el contenido de cada secci√≥n.
  - **Mensajes:** section_start, section_chunk, section_end, summary_update.
  - **Nota sobre Rendimiento:** La m√©trica de rendimiento de renderizado de la UI (PERF-002) es propiedad de la tarea T-07 y no se mide aqu√≠.

- **Estrategia de Test:**
  - **Integration Tests:** Simular un cliente WebSocket que se conecta, recibe el stream de una secci√≥n completa y verifica que el contenido es coherente. Medir la latencia del handshake y del stream.
- **Documentaci√≥n:**
  - Documentar el protocolo de mensajes del WebSocket.
- **Criterios de Aceptaci√≥n:**
  - La generaci√≥n de una secci√≥n de 600 tokens se completa en ‚â§ 20 segundos (p95).
  - El handshake de la conexi√≥n WebSocket se completa en ‚â§ 150 ms.
  - El global_summary se actualiza en ‚â§ 500 ms (p95) tras la finalizaci√≥n de cada secci√≥n.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests de integraci√≥n pasan.
  - Documentaci√≥n del protocolo WS completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                                         |                      |                                                                                                                         |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | -------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                              | Complejidad Estimada | Entregable Verificable                                                                                                  |
| R1.WP2-T06-ST1                   | Implementar el servidor WebSocket, incluyendo el handshake de conexi√≥n y la autenticaci√≥n del usuario.                  | 5                    | Test de integraci√≥n que establece una conexi√≥n WS autenticada y verifica que el handshake se completa en < 150 ms.      |
| R1.WP2-T06-ST2                   | Desarrollar la l√≥gica de streaming de secciones, que toma el outline de T-05 y genera el contenido secci√≥n por secci√≥n. | 6                    | Test que invoca el flujo de generaci√≥n y verifica que el servidor WS emite eventos de section_chunk y section_complete. |
| R1.WP2-T06-ST3                   | Implementar la generaci√≥n y refresco del global_summary despu√©s de cada secci√≥n completada.                             | 3                    | Test que verifica que tras un evento section_complete, se emite un evento summary_update con el resumen actualizado.    |

---

### **Tarea T-07: Editor UI Core + Split View**

- **ID de Tarea:** T-07
- **T√≠tulo:** Editor UI Core + Split View
- **Estado:** Pendiente
- **Dependencias:** T-06
- **Prioridad:** Alta
- **Release Target:** Release 2
- **Descripci√≥n:** Construir la interfaz de usuario principal para la edici√≥n de documentos. Esta interfaz debe ser una vista dividida (split-view) que muestre el outline del documento, el contenido principal y una barra de prompts interactiva. Esta tarea consolida y asume la propiedad de la m√©trica de rendimiento PERF-002 (< 200 ms render), medida a trav√©s de Lighthouse.
- **Detalles T√©cnicos:**
  - **Framework:** React 18.
  - **Editor:** Monaco Editor.
  - **Estado:** Zustand o Redux Toolkit para la gesti√≥n del estado del documento.
  - **Componentes:** SplitView, OutlinePane, EditorPane, PromptBar.
- **Estrategia de Test:**
  - **Unit Tests:** Para los componentes de UI y la l√≥gica de estado.
  - **E2E Tests (Cypress):** Probar la interacci√≥n del usuario, como el drag-and-drop de secciones en el outline.
  - **Performance Tests:** Medir el tiempo de renderizado inicial con Lighthouse (PERF-002).
- **Documentaci√≥n:**
  - Storybook para los componentes de la UI del editor.
- **Criterios de Aceptaci√≥n:**
  - El tiempo de renderizado inicial de la vista del editor es < 200 ms (p95) seg√∫n Lighthouse.
  - El reordenamiento de secciones mediante drag-and-drop en el Outline Pane persiste en el estado de la aplicaci√≥n.
  - La ETA en la Prompt Bar muestra un progreso con una precisi√≥n de ¬±5%.
  - El editor Monaco est√° configurado seg√∫n las directrices de DESIGN_GUIDELINES.md.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, E2E, performance) pasan.
  - Documentaci√≥n en Storybook completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                                     |                      |                                                                                                                                 |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                          | Complejidad Estimada | Entregable Verificable                                                                                                          |
| R2.WP1-T07-ST1                   | Implementar el layout de Split View con React, integrando el editor Monaco y un panel de outline.                   | 5                    | Componente React renderiza la vista dividida. El editor Monaco est√° configurado seg√∫n DESIGN_GUIDELINES.md.                     |
| R2.WP1-T07-ST2                   | Desarrollar el componente "Prompt Bar" con c√°lculo y visualizaci√≥n de ETA din√°mica, conect√°ndose al stream de T-06. | 4                    | La barra de progreso se actualiza durante la generaci√≥n de contenido y la ETA es visible.                                       |
| R2.WP1-T07-ST3                   | Implementar el "Outline Pane" con funcionalidad de drag-and-drop para reordenar secciones.                          | 5                    | Test Cypress que arrastra un heading en el panel de outline y verifica que el orden se actualiza en el estado de la aplicaci√≥n. |

---

### **Tarea T-08: Action Palette + IA Cmds**

- **ID de Tarea:** T-08
- **T√≠tulo:** Action Palette + IA Cmds
- **Estado:** Pendiente
- **Dependencias:** T-07, T-41
- **Prioridad:** Alta
- **Release Target:** Release 2
- **Descripci√≥n:** Dotar al editor de una paleta de acciones (similar a VS Code) que permita al usuario invocar comandos de IA para reescribir, resumir, expandir o modificar el texto seleccionado.
- **Detalles T√©cnicos:**
  - **UI:** Librer√≠a como cmdk para la paleta de acciones.
  - **Backend:** Endpoint POST /rewrite que recibe texto, un comando y contexto.
  - **IA:** Prompts espec√≠ficos para cada comando de reescritura.
  - **QA:** Test harness para validar la calidad de la salida de los comandos (ROUGE-L).
- **Estrategia de Test:**
  - **Unit Tests (Jest):** Probar los comandos de reescritura con textos "golden" para verificar la calidad sem√°ntica (ROUGE-L).
  - **Integration Tests:** Probar el flujo completo desde la paleta de acciones hasta la actualizaci√≥n del texto en el editor.
- **Documentaci√≥n:**
  - Documentar los comandos de IA disponibles y su funcionamiento.
- **Criterios de Aceptaci√≥n:**
  - El comando /resume reduce el texto en al menos un 20% y obtiene un score ROUGE-L ‚â• 0.7 contra un resumen de referencia.
  - Un test demuestra que una reescritura que introduce una incoherencia contextual es marcada o rechazada por el sistema.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration) pasan.
  - Documentaci√≥n de comandos completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                          |                      |                                                                                                      |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ | -------------------- | ---------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                               | Complejidad Estimada | Entregable Verificable                                                                               |
| R2.WP1-T08-ST1                   | Integrar una paleta de acciones (ej. cmdk) en el editor y registrar los 8 comandos b√°sicos.                              | 4                    | La paleta de acciones se abre con un atajo de teclado y muestra los comandos disponibles.            |
| R2.WP1-T08-ST2                   | Implementar el endpoint de backend /rewrite que toma texto y un comando (ej. "summarize") y devuelve el texto reescrito. | 4                    | Colecci√≥n Postman que prueba el endpoint /rewrite con diferentes comandos y verifica las respuestas. |
| R2.WP1-T08-ST3                   | Crear el test harness con ROUGE-L para validar la calidad de los comandos de reescritura.                                | 4                    | Script de test que ejecuta el comando /resume sobre un texto de referencia y falla si ROUGE-L < 0.7. |

---

### **Tarea T-09: Versioning & Diff**

- **ID de Tarea:** T-09
- **T√≠tulo:** Versioning & Diff
- **Estado:** Pendiente
- **Dependencias:** T-07, T-13
- **Prioridad:** Alta
- **Release Target:** Release 4
- **Descripci√≥n:** Implementar un sistema de versionado autom√°tico para cada documento. El sistema guardar√° un snapshot cada vez que el usuario guarde, permitiendo ver las diferencias entre versiones y revertir a una versi√≥n anterior.
- **Detalles T√©cnicos:**
  - **Backend:** Almacenar snapshots del documento en una tabla separada, vinculada al documento principal. Usar SHA-256 para identificar cambios.
  - **Frontend:** Usar el componente DiffEditor de Monaco para visualizar las diferencias.
  - **L√≠mite:** Implementar un l√≠mite de 500 versiones por documento para controlar el almacenamiento.
- **Estrategia de Test:**
  - **Unit Tests:** Para la l√≥gica de creaci√≥n de snapshots y el c√°lculo de hashes.
  - **E2E Tests (Cypress):** Probar el flujo completo: guardar varias veces, abrir el visor de versiones, seleccionar una versi√≥n, ver el diff y revertir a ella.
- **Documentaci√≥n:**
  - Documentar c√≥mo funciona el sistema de versionado.
- **Criterios de Aceptaci√≥n:**
  - La acci√≥n de revertir a una versi√≥n vN restaura el contenido correctamente sin perder el historial de versiones posterior.
  - Cada guardado de un documento se registra como un evento en el log de auditor√≠a de T-13.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, E2E) pasan.
  - Documentaci√≥n completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                                                |                      |                                                                                                                                 |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                     | Complejidad Estimada | Entregable Verificable                                                                                                          |
| R4.WP1-T09-ST1                   | Modificar el modelo de datos para almacenar snapshots de documentos (contenido + SHA-256) y registrar el evento en el log de auditor√≠a (T-13). | 4                    | Test que guarda un documento y verifica que se crea un nuevo registro de versi√≥n en la DB y una entrada en el log de auditor√≠a. |
| R4.WP1-T09-ST2                   | Implementar el componente de UI DiffEditor (de Monaco) que muestra las diferencias entre la versi√≥n actual y una seleccionada.                 | 5                    | Componente React que, dados dos textos, renderiza una vista de diferencias.                                                     |
| R4.WP1-T09-ST3                   | Implementar la funcionalidad de "Rollback" en la UI y el endpoint de backend correspondiente que restaura una versi√≥n anterior.                | 3                    | Test Cypress que selecciona una versi√≥n antigua, hace clic en "Rollback" y verifica que el contenido del editor se actualiza.   |

---

### **Tarea T-10: Export Service**

- **ID de Tarea:** T-10
- **T√≠tulo:** Export Service
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Media
- **Release Target:** Release 4
- **Descripci√≥n:** Crear un servicio as√≠ncrono que permita a los usuarios exportar sus documentos (que est√°n en formato Markdown) a formatos comunes como PDF y DOCX.
- **Detalles T√©cnicos:**
  - **Asincron√≠a:** Celery con un broker (Redis o RabbitMQ).
  - **Conversi√≥n:** Librer√≠a Pandoc.
  - **UI:** Bot√≥n de exportaci√≥n y notificaciones "toast" para informar al usuario del progreso.
- **Estrategia de Test:**
  - **Integration Tests:** Una tarea de Celery que toma un string Markdown y verifica que los archivos PDF y DOCX generados son v√°lidos.
  - **E2E Tests (Cypress):** Probar el flujo desde el clic en "Exportar" hasta la descarga del archivo.
- **Documentaci√≥n:**
  - ADR sobre la elecci√≥n de Celery y Pandoc.
- **Criterios de Aceptaci√≥n:**
  - El archivo PDF generado se abre en visores est√°ndar sin advertencias de formato.
  - El archivo DOCX generado pasa la validaci√≥n del validador de OpenXML.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - Documentaci√≥n (ADR) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 10)**

|                                  |                                                                                                       |                      |                                                                                                                         |
| -------------------------------- | ----------------------------------------------------------------------------------------------------- | -------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                            | Complejidad Estimada | Entregable Verificable                                                                                                  |
| R4.WP1-T10-ST1                   | Configurar Celery y un broker (ej. Redis/RabbitMQ) para gestionar tareas as√≠ncronas de exportaci√≥n.   | 4                    | Tarea de prueba "hello world" se ejecuta correctamente a trav√©s de Celery.                                              |
| R4.WP1-T10-ST2                   | Implementar la tarea de Celery que utiliza Pandoc para convertir el contenido Markdown a PDF y DOCX.  | 4                    | La tarea toma un string Markdown y genera un fichero PDF y DOCX v√°lidos.                                                |
| R4.WP1-T10-ST3                   | Integrar la funcionalidad en la UI con un bot√≥n de "Exportar" y un toast de notificaci√≥n de progreso. | 2                    | Test Cypress que hace clic en "Exportar", verifica que se muestra el toast y que el archivo se descarga al completarse. |

---

### **Tarea T-11: Coherence Checker**

- **ID de Tarea:** T-11
- **T√≠tulo:** Coherence Checker
- **Estado:** Pendiente
- **Dependencias:** T-06
- **Prioridad:** Alta
- **Release Target:** Release 2
- **Descripci√≥n:** Desarrollar un servicio que pueda analizar el texto completo de un documento y proporcionar una puntuaci√≥n de coherencia. Esto ayuda a los editores a identificar inconsistencias l√≥gicas o estil√≠sticas introducidas durante la generaci√≥n o edici√≥n.
- **Detalles T√©cnicos:**
  - **IA:** Modelo de lenguaje pre-entrenado (tipo BERT) para la clasificaci√≥n de coherencia o "Next Sentence Prediction".
  - **Backend:** Endpoint POST /revise_global.
  - **Investigaci√≥n:** Requiere una fase de I+D para seleccionar y ajustar el modelo m√°s adecuado.
- **Estrategia de Test:**
  - **Unit Tests:** Crear un dataset de prueba con pares de textos (coherentes e incoherentes) y verificar que el modelo los clasifica correctamente.
- **Documentaci√≥n:**
  - ADR documentando la investigaci√≥n, la elecci√≥n del modelo y los resultados de la validaci√≥n.
- **Criterios de Aceptaci√≥n:**
  - El clasificador de coherencia alcanza una tasa de error ‚â§ 1% en el dataset de prueba curado.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests unitarios con el dataset de prueba pasan.
  - Documentaci√≥n (ADR) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 15)**

|                                  |                                                                                                             |                      |                                                                                                                          |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                  | Complejidad Estimada | Entregable Verificable                                                                                                   |
| R2.WP2-T11-ST1                   | Investigar y seleccionar un modelo pre-entrenado (BERT-based) para la evaluaci√≥n de cohesi√≥n textual.       | 4                    | ADR documentando la elecci√≥n del modelo, sus pros y contras, y c√≥mo integrarlo.                                          |
| R2.WP2-T11-ST2                   | Implementar el endpoint /revise_global que toma el contenido del documento y devuelve un score de cohesi√≥n. | 6                    | Colecci√≥n Postman que env√≠a un texto coherente (score alto) y uno incoherente (score bajo) y verifica los resultados.    |
| R2.WP2-T11-ST3                   | Crear un dataset de prueba con ejemplos de textos coherentes e incoherentes para validar el checker.        | 5                    | Test de integraci√≥n que ejecuta el checker contra el dataset y verifica que la precisi√≥n es la esperada (‚â§ 1% de error). |

---

### **Tarea T-12: Credential Store & Crypto**

- **ID de Tarea:** T-12
- **T√≠tulo:** Credential Store & Crypto
- **Estado:** Pendiente
- **Dependencias:** T-13
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Implementar las medidas criptogr√°ficas fundamentales para proteger los datos de la aplicaci√≥n, tanto en reposo (at-rest) como en tr√°nsito (in-transit), y establecer un proceso para la rotaci√≥n autom√°tica de credenciales.
- **Detalles T√©cnicos:**
  - **Cifrado en Reposo:** AES-256 para datos sensibles en la DB (ej. claves de API de usuario).
  - **Cifrado en Tr√°nsito:** Forzar TLS 1.3 en todas las comunicaciones.
  - **Rotaci√≥n de Claves:** Cron job que identifica y fuerza la rotaci√≥n de claves de API de usuario con m√°s de 90 d√≠as.
- **Estrategia de Test:**
  - **Unit Tests:** Para las funciones de cifrado y descifrado.
  - **Integration Tests:** Probar el cron job de rotaci√≥n de claves.
  - **Security Tests:** Realizar un pentest b√°sico para verificar la configuraci√≥n de TLS y que los datos sensibles no se almacenan en texto plano.
- **Documentaci√≥n:**
  - ADR sobre la estrategia de gesti√≥n de secretos.
- **Criterios de Aceptaci√≥n:**
  - Una simulaci√≥n de una clave de 91 d√≠as de antig√ºedad dispara la rotaci√≥n autom√°tica y genera una entrada en el log WORM en ‚â§ 5 minutos.
  - La clave antigua queda invalidada despu√©s de la rotaci√≥n.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration, security) pasan.
  - Documentaci√≥n (ADR) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                         |                      |                                                                                                                             |
| -------------------------------- | ------------------------------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                              | Complejidad Estimada | Entregable Verificable                                                                                                      |
| R0.WP3-T12-ST1                   | Implementar la encriptaci√≥n AES-256 para los datos sensibles en reposo (at-rest) en la base de datos.   | 5                    | Test unitario que encripta un dato, lo guarda, lo recupera y lo desencripta, verificando que el valor original se mantiene. |
| R0.WP3-T12-ST2                   | Configurar el servidor web para forzar TLS 1.3 en todas las comunicaciones (in-transit).                | 3                    | Reporte de una herramienta como SSL Labs que confirma que el servidor usa TLS 1.3 y tiene una configuraci√≥n segura.         |
| R0.WP3-T12-ST3                   | Crear el cron job diario que identifica claves API de usuario con m√°s de 90 d√≠as de antig√ºedad.         | 3                    | Script que, al ejecutarse, imprime una lista de las claves que necesitan rotaci√≥n.                                          |
| R0.WP3-T12-ST4                   | Implementar la l√≥gica de rotaci√≥n autom√°tica de claves y el registro del evento en el log de auditor√≠a. | 3                    | Test que simula una clave de 91 d√≠as y verifica que se genera una nueva clave y se registra el evento en el log WORM.       |

---

### **Tarea T-13: Audit Log WORM & Viewer**

- **ID de Tarea:** T-13
- **T√≠tulo:** Audit Log WORM & Viewer
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Crear un sistema de registro de auditor√≠a inmutable (WORM - Write Once, Read Many) para todas las acciones cr√≠ticas del sistema. Tambi√©n se debe proporcionar una interfaz para que los administradores puedan visualizar y filtrar estos logs.
- **Detalles T√©cnicos:**
  - **Backend:** Tabla en la base de datos con permisos de INSERT y SELECT √∫nicamente para el usuario de la aplicaci√≥n.
  - **Frontend:** Interfaz de visualizaci√≥n para administradores con filtros por usuario, tipo de acci√≥n y rango de fechas.
- **Estrategia de Test:**
  - **Integration Tests:** Realizar una acci√≥n cr√≠tica (ej. login, guardar documento) y verificar que se crea la entrada correcta en el log de auditor√≠a.
  - **Security Tests:** Intentar modificar o eliminar un registro del log y verificar que la operaci√≥n falla.
  - **E2E Tests (Cypress):** Probar la interfaz del visor de logs, incluyendo la paginaci√≥n y los filtros.
- **Criterios de Aceptaci√≥n:**
  - Una entrada en el log WORM aparece en ‚â§ 5 segundos tras la acci√≥n correspondiente.
  - La UI del visor de logs permite filtrar por usuario, tipo de acci√≥n y rango de fechas, con paginaci√≥n funcional.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, security, E2E) pasan.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 11)**

|                                  |                                                                                                                               |                      |                                                                                                                                 |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                    | Complejidad Estimada | Entregable Verificable                                                                                                          |
| R0.WP3-T13-ST1                   | Dise√±ar y crear la tabla de base de datos para el log de auditor√≠a con una pol√≠tica de append-only a nivel de permisos de DB. | 4                    | Script de migraci√≥n de la base de datos. Un test que intenta un UPDATE o DELETE en la tabla falla debido a los permisos.        |
| R0.WP3-T13-ST2                   | Implementar el servicio de logging que escribe eventos en la tabla de auditor√≠a.                                              | 4                    | Test de integraci√≥n que realiza una acci√≥n (ej. guardar documento) y verifica que se crea la entrada correspondiente en el log. |
| R0.WP3-T13-ST3                   | Desarrollar la UI del visor de logs para administradores, incluyendo filtros por usuario, acci√≥n y fecha.                     | 3                    | Test Cypress donde un admin filtra el log y verifica que los resultados son correctos.                                          |

---

### **Tarea T-14: Observability & Dashboards + KPIs**

- **ID de Tarea:** T-14
- **T√≠tulo:** Observability & Dashboards + KPIs
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Alta
- **Release Target:** Release 5
- **Descripci√≥n:** Implementar una soluci√≥n de observabilidad completa para monitorizar la salud, el rendimiento y el uso del sistema. Esto incluye la recolecci√≥n de trazas, m√©tricas y logs, y su visualizaci√≥n en dashboards.
- **Detalles T√©cnicos:**
  - **Est√°ndar:** OpenTelemetry (OTel) para la instrumentaci√≥n.
  - **Stack:** Prometheus para m√©tricas, Grafana para dashboards, y un colector OTel (como Jaeger o Grafana Tempo) para trazas.
  - **KPIs:** TMG, ratio de √©xito de ingesta, reutilizaci√≥n de plantillas, etc.
- **Estrategia de Test:**
  - **Integration Tests:** Verificar que las m√©tricas y trazas personalizadas se exportan y son visibles en Grafana/Jaeger.
- **Documentaci√≥n:**
  - Documentar las m√©tricas personalizadas que se exponen.
  - Exportar la configuraci√≥n de los dashboards de Grafana como JSON.
- **Criterios de Aceptaci√≥n:**
  - El 99% de los spans de una transacci√≥n est√°n instrumentados y son visibles en el sistema de trazas.
  - Un panel de Grafana muestra los KPIs clave (TMG, doc_count/month, etc.) con un lag de datos < 60 segundos.
  - Se han configurado alertas para los umbrales de cada KPI.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests de integraci√≥n pasan.
  - Documentaci√≥n y dashboards exportados completados.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 13)**

|                                  |                                                                                                              |                      |                                                                                                               |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------ | -------------------- | ------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                   | Complejidad Estimada | Entregable Verificable                                                                                        |
| R5.WP1-T14-ST1                   | Instrumentar el c√≥digo de backend y frontend con OpenTelemetry (OTel) para generar trazas y m√©tricas.        | 5                    | Trazas de una petici√≥n E2E (frontend -> backend -> DB) son visibles en un colector OTel (ej. Jaeger).         |
| R5.WP1-T14-ST2                   | Configurar Prometheus para recolectar m√©tricas y Grafana para la visualizaci√≥n.                              | 4                    | Una m√©trica custom (ej. documents_created_total) es visible y se actualiza en un dashboard de Grafana.        |
| R5.WP1-T14-ST3                   | Crear los dashboards de Grafana con los KPIs definidos (TMG, ratio de √©xito, etc.) y configurar las alertas. | 4                    | Screenshots de los dashboards de Grafana mostrando los KPIs. Una regla de alerta configurada para el KPI TMG. |

---

### **Tarea T-15: Backup & Storage Ops**

- **ID de Tarea:** T-15
- **T√≠tulo:** Backup & Storage Ops
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 5
- **Descripci√≥n:** Establecer y automatizar las operaciones de respaldo y restauraci√≥n para garantizar la durabilidad de los datos y la resiliencia del sistema. Incluye la gesti√≥n de pol√≠ticas de retenci√≥n y alertas de almacenamiento.
- **Detalles T√©cnicos:**
  - **Scripts:** Scripts de shell/Python para pg_dump (o similar) y backup del vector-store.
  - **Almacenamiento:** Soluci√≥n de almacenamiento de objetos compatible con S3 para los backups.
  - **Cifrado:** GPG o similar para cifrar los archivos de backup.
  - **Automatizaci√≥n:** Cron jobs o jobs de CI/CD programados.
- **Estrategia de Test:**
  - **Integration Tests:** El job de CI/CD restore --verify (T-29) es el principal test de integraci√≥n para esta tarea.
  - **E2E Tests:** Simular un escenario de desastre y medir el tiempo de recuperaci√≥n manual usando los scripts.
- **Documentaci√≥n:**
  - Documento de runbook para el proceso de backup y restauraci√≥n manual.
- **Criterios de Aceptaci√≥n:**
  - Un job de CI/CD semanal ejecuta restore --verify y comprueba el hash del backup restaurado contra el original.
  - Una alerta se dispara cuando el uso del almacenamiento de backups supera el 80% de la cuota.
  - Los backups con m√°s de 30 d√≠as de antig√ºedad son purgados autom√°ticamente por un script de retenci√≥n.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - El job de restore --verify pasa consistentemente.
  - Documentaci√≥n (runbook) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 10)**

|                                  |                                                                                                                   |                      |                                                                                                           |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                        | Complejidad Estimada | Entregable Verificable                                                                                    |
| R5.WP2-T15-ST1                   | Crear y programar el script de backup diario encriptado de la base de datos y el vector-store.                    | 4                    | Job de CI/CD que se ejecuta diariamente y produce un fichero de backup encriptado en un storage seguro.   |
| R5.WP2-T15-ST2                   | Desarrollar el script de restauraci√≥n que toma un backup y restaura el estado del sistema en un entorno temporal. | 4                    | El script restaura una base de datos en un entorno de staging y un test de sanidad pasa correctamente.    |
| R5.WP2-T15-ST3                   | Implementar la pol√≠tica de retenci√≥n de 30 d√≠as y la alerta de cuota al 80%.                                      | 2                    | Script que purga backups con m√°s de 30 d√≠as. Una alerta se dispara cuando el uso del disco supera el 80%. |

---

### **Tarea T-16: Deployment & Scaling (PoC)**

- **ID de Tarea:** T-16
- **T√≠tulo:** Deployment & Scaling (PoC)
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Realizar una Prueba de Concepto (PoC) para validar la estrategia de despliegue y escalado de la aplicaci√≥n en un entorno orquestado como Kubernetes. El objetivo es demostrar la capacidad de auto-escalado y la viabilidad del sharding del vector-store.
- **Detalles T√©cnicos:**
  - **Orquestaci√≥n:** Kubernetes (Minikube o similar para el PoC).
  - **Manifiestos:** YAML para Deployments, Services, HPA (Horizontal Pod Autoscaler).
  - **Vector Store Sharding:** PoC con Qdrant o Chroma en modo cl√∫ster.
  - **Test de Carga:** Locust para generar carga y disparar el auto-escalado.
- **Estrategia de Test:**
  - **Performance Tests:** Ejecutar el test de carga y observar las m√©tricas de HPA y el n√∫mero de pods.
  - **Chaos Tests:** Simular la ca√≠da de un pod de la aplicaci√≥n y medir el tiempo de recuperaci√≥n (MTTR).
- **Documentaci√≥n:**
  - ADR con los resultados del PoC, incluyendo m√©tricas de rendimiento y lecciones aprendidas.
- **Criterios de Aceptaci√≥n:**
  - Un test de carga con 10 usuarios y 100 documentos dispara el escalado de la aplicaci√≥n a ‚â• 3 r√©plicas.
  - El PoC demuestra la distribuci√≥n de datos y consultas a trav√©s de ‚â• 2 shards del vector-store.
  - El tiempo medio de recuperaci√≥n (MTTR) ante el fallo de un pod de la aplicaci√≥n es ‚â§ 2 horas (en el PoC).
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (manifiestos, scripts) revisado y aprobado.
  - Todos los tests (performance, chaos) del PoC completados y sus resultados documentados.
  - Documentaci√≥n (ADR) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                                       |                      |                                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                            | Complejidad Estimada | Entregable Verificable                                                                                                       |
| R4.WP3-T16-ST1                   | Crear manifiestos de Kubernetes (Deployment, Service, HPA) para los servicios de aplicaci√≥n.                                          | 4                    | kubectl apply -f . despliega la aplicaci√≥n en un cl√∫ster de k8s. El HPA est√° configurado para escalar basado en CPU/memoria. |
| R4.WP3-T16-ST2                   | Realizar un PoC de sharding para el vector-store (Qdrant/Chroma), documentando la configuraci√≥n y el m√©todo de distribuci√≥n.          | 5                    | Documento ADR y un script que demuestra que las consultas se distribuyen entre al menos dos shards del vector-store.         |
| R4.WP3-T16-ST3                   | Ejecutar un test de carga (Locust) que demuestre que el HPA escala las r√©plicas de la aplicaci√≥n cuando se supera el umbral de carga. | 3                    | M√©tricas de Grafana/Prometheus que muestran el aumento del n√∫mero de pods durante el test de carga.                          |

---

### **Tarea T-17: API-SPEC & ADR Governance**

- **ID de Tarea:** T-17
- **T√≠tulo:** API-SPEC & ADR Governance
- **Estado:** Completado
- **Dependencias:** T-01
- **Prioridad:** Alta
- **Release Target:** Release 0
- **Descripci√≥n:** Establecer un proceso de gobernanza automatizado para la documentaci√≥n de la arquitectura y la API. Esto asegura que la documentaci√≥n se mantenga actualizada, sea consistente y trazable a lo largo del proyecto. **El alcance incluye la creaci√≥n de una plantilla est√°ndar para "Actas de Certificaci√≥n" de tareas cr√≠ticas.**
- **Detalles T√©cnicos:**
  - **API Spec:** OpenAPI 3.1.
  - **Linting:** spectral para validar la especificaci√≥n OpenAPI.
  - **Trazabilidad:** Script que parsea los requisitos y el plan de trabajo para generar una matriz de trazabilidad.
  - **Automatizaci√≥n:** Job de CI en GitHub Actions.
- **Estrategia de Test:**
  - **Integration Tests:** El propio job de CI act√∫a como test. Un PR con una OpenAPI inv√°lida o una matriz de trazabilidad desactualizada debe hacer fallar el pipeline.
- **Documentaci√≥n:**
  - La tarea consiste en automatizar la generaci√≥n y validaci√≥n de la propia documentaci√≥n.
- **Criterios de Aceptaci√≥n:**
  - El linter spectral se ejecuta en CI y no reporta errores en la especificaci√≥n OpenAPI.
  - La matriz de trazabilidad (docs/traceability.xlsx) se genera y versiona en cada commit a main.
  - El √≠ndice de ADRs est√° actualizado.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (scripts, config CI) revisado y aprobado.
  - El job de CI de gobernanza pasa correctamente.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 8)**

|                                  |                                                                                                                                |                      |                                                                                                                  |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | -------------------- | ---------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                     | Complejidad Estimada | Entregable Verificable                                                                                           |
| R0.WP1-T17-ST1                   | Integrar spectral en el pipeline de CI para validar el fichero OpenAPI 3.1 en cada commit.                                     | 2                    | El pipeline de CI falla si se introduce un cambio no v√°lido en la especificaci√≥n OpenAPI.                        |
| R0.WP1-T17-ST2                   | Crear el script que genera la matriz de trazabilidad (traceability.xlsx) y a√±adirlo como artefacto de CI.                      | 3                    | El pipeline de CI genera y adjunta el fichero traceability.xlsx en cada ejecuci√≥n.                               |
| R0.WP1-T17-ST3                   | Escribir los ADRs iniciales para decisiones clave (ej. elecci√≥n de Celery, estrategia de chunking).                            | 1                    | Ficheros ADR correspondientes existen en el directorio /docs/adr.                                                |
| R0.WP1-T17-ST4                   | Crear ADR para el Modelo de Gesti√≥n de API Keys de Usuario (relacionado a T-41), y la plantilla para "Actas de Certificaci√≥n". | 2                    | Fichero ADR-XXX-api-key-management-model.md y la plantilla de Acta de Certificaci√≥n existen y est√°n versionados. |

---

### **Tarea T-18: Context Flags & Template Selection**

- **ID de Tarea:** T-18
- **T√≠tulo:** Context Flags & Template Selection
- **Estado:** Pendiente
- **Dependencias:** T-32
- **Prioridad:** Alta
- **Release Target:** Release 3
- **Descripci√≥n:** Implementar controles en la UI que permitan al usuario seleccionar el contexto para la generaci√≥n de IA (usar base de conocimiento, b√∫squeda web o libre) y elegir una plantilla de prompt predefinida.
- **Detalles T√©cnicos:**
  - **UI:** Componentes Toggle y Dropdown en React.
  - **Backend:** Endpoint PATCH /context para persistir la selecci√≥n del usuario por documento.
  - **L√≥gica:** El servicio de generaci√≥n debe leer esta configuraci√≥n y ajustar su comportamiento (ej. no realizar b√∫squeda RAG si el contexto es "Libre").
- **Estrategia de Test:**
  - **Unit Tests:** Probar la l√≥gica del backend que ajusta el comportamiento de generaci√≥n seg√∫n el contexto.
  - **E2E Tests (Cypress):** Probar que cambiar el toggle o seleccionar una plantilla en la UI se refleja en la siguiente generaci√≥n de contenido.
- **Documentaci√≥n:**
  - Actualizar la documentaci√≥n de la API para el endpoint /context.
- **Criterios de Aceptaci√≥n:**
  - Cambiar el toggle de contexto en la UI aplica el contexto y excluye la b√∫squeda RAG en ‚â§ 3 segundos (p95).
  - El dropdown muestra y aplica la plantilla seleccionada de T-32.
  - El toggle "Web search" est√° presente pero deshabilitado, y al pasar el cursor sobre √©l muestra el tooltip: "Disponible en futura versi√≥n".
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, E2E) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 11)**

|                                  |                                                                                                                        |                      |                                                                                                                                                            |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                             | Complejidad Estimada | Entregable Verificable                                                                                                                                     |
| R3.WP2-T18-ST1                   | Implementar el componente de UI con el toggle de contextos (KB, Web, Libre) y el dropdown de plantillas.               | 4                    | Componente React renderiza los controles. El toggle "Web search" est√° deshabilitado con el tooltip correcto.                                               |
| R3.WP2-T18-ST2                   | Implementar el endpoint API /context (PATCH) que actualiza las preferencias del usuario para un documento.             | 3                    | Colecci√≥n Postman que actualiza el contexto y la plantilla de un documento.                                                                                |
| R3.WP2-T18-ST3                   | Conectar la UI al backend y a√±adir tests que verifiquen que la selecci√≥n de contexto/plantilla afecta a la generaci√≥n. | 4                    | Test Cypress que selecciona "Libre" y verifica que no se hace una b√∫squeda RAG. Otro test que selecciona una plantilla y verifica que se usa en el prompt. |

---

### **Tarea T-19: Comment Tags & /comment CRUD**

- **ID de Tarea:** T-19
- **T√≠tulo:** Comment Tags & /comment CRUD
- **Estado:** Pendiente
- **Dependencias:** T-07
- **Prioridad:** Media
- **Release Target:** Release 3
- **Descripci√≥n:** Implementar una funcionalidad de comentarios en el editor. Los usuarios podr√°n a√±adir comentarios tipo "tag" (ej. TODO, NOTE) en l√≠neas espec√≠ficas del texto, que ser√°n visibles como decoraciones y estar√°n enlazados con el panel de outline.
- **Detalles T√©cnicos:**
  - **Backend:** API REST para el CRUD de comentarios (/comment).
  - **Frontend:** Usar las decoraciones de Monaco Editor para mostrar los tags en el gutter o en el propio texto.
  - **Estado:** Sincronizar los comentarios entre el editor y un posible panel de comentarios.
- **Estrategia de Test:**
  - **Unit Tests (Jest):** Cobertura > 90% para la l√≥gica de estado de los comentarios en el frontend.
  - **Integration Tests:** Probar el CRUD de la API de comentarios.
  - **E2E Tests (Cypress):** Probar el flujo completo de a√±adir un comentario desde la UI y verificar que persiste.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para los endpoints de /comment.
- **Criterios de Aceptaci√≥n:**
  - Crear o eliminar un tag se refleja en la UI en < 150 ms.
  - Los tests de Jest para la l√≥gica de comentarios tienen una cobertura > 90%.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration, E2E) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 10)**

|                                  |                                                                                                    |                      |                                                                                                           |
| -------------------------------- | -------------------------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                         | Complejidad Estimada | Entregable Verificable                                                                                    |
| R3.WP1-T19-ST1                   | Implementar los endpoints REST para el CRUD de comentarios (/comment).                             | 4                    | Colecci√≥n Postman que prueba la creaci√≥n, listado y eliminaci√≥n de comentarios asociados a un documento.  |
| R3.WP1-T19-ST2                   | Integrar las decoraciones de Monaco Editor para visualizar los tags (TODO, NOTE) en el texto.      | 3                    | Al a√±adir un comentario con un tag, una decoraci√≥n visual aparece en la l√≠nea correspondiente del editor. |
| R3.WP1-T19-ST3                   | Conectar la UI al backend y asegurar que los comentarios se pueden crear/eliminar desde el editor. | 3                    | Test Cypress que a√±ade un comentario a trav√©s de la UI y verifica que persiste tras recargar la p√°gina.   |

---

### **Tarea T-20: Bench E2E Performance**

- **ID de Tarea:** T-20
- **T√≠tulo:** Bench E2E Performance
- **Estado:** Pendiente
- **Dependencias:** T-08, T-10
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Crear y ejecutar una suite de benchmarks de rendimiento End-to-End (E2E) que simule el ciclo de vida completo de un documento bajo una carga de usuarios realista.
- **Detalles T√©cnicos:**
  - **Herramientas:** JMeter para la ingesta masiva, Locust para la simulaci√≥n de usuarios interactivos.
  - **Escenario:** 1. Ingesta de 100 documentos. 2. 10 usuarios concurrentes realizan acciones de generaci√≥n, edici√≥n y exportaci√≥n sobre esos documentos.
- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma una tarea de testing.
- **Documentaci√≥n:**
  - Documentar los scripts de benchmark y c√≥mo ejecutarlos.
  - Generar un reporte final de rendimiento con los resultados.
- **Criterios de Aceptaci√≥n:**
  - El p95 del tiempo total para el flujo (generaci√≥n + edici√≥n + exportaci√≥n) es ‚â§ 6 minutos.
  - El p95 del tiempo para completar un borrador (draft_complete_p95) es ‚â§ 8 minutos.
  - Las pruebas est√°n automatizadas y se ejecutan en un job de CI.
- **Definici√≥n de Hecho (DoD):**
  - Scripts de benchmark revisados y aprobados.
  - Reportes de JMeter y Locust generados y analizados.
  - El job de CI est√° configurado.
  - **Acta de Certificaci√≥n del Ciclo de KPI de Rendimiento (seg√∫n plantilla de T-17) firmada por el Tech Lead.**
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                                 |                      |                                                                                                                                  |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                      | Complejidad Estimada | Entregable Verificable                                                                                                           |
| R6.WP3-T20-ST1                   | Desarrollar el script de JMeter que simula el flujo de ingesta masiva de 100 documentos.                                        | 4                    | Reporte de JMeter mostrando los tiempos de subida de los 100 documentos.                                                         |
| R6.WP3-T20-ST2                   | Desarrollar el script de Locust que simula a 10 usuarios concurrentes realizando acciones de generaci√≥n, edici√≥n y exportaci√≥n. | 5                    | Reporte de Locust mostrando las m√©tricas de latencia p95 para las acciones bajo carga.                                           |
| R6.WP3-T20-ST3                   | Integrar la ejecuci√≥n de estos scripts en un job de CI (manual o nocturno) que falle si se degradan las m√©tricas clave.         | 3                    | Configuraci√≥n del job de CI. Un log de ejecuci√≥n que muestra un resultado "pass" o "fail" basado en los umbrales de rendimiento. |

---

### **Tarea T-21: Navigation & Accessibility**

- **ID de Tarea:** T-21
- **T√≠tulo:** Navigation & Accessibility
- **Estado:** Pendiente
- **Dependencias:** T-07
- **Prioridad:** Alta
- **Release Target:** Release 3
- **Descripci√≥n:** Mejorar la navegaci√≥n global de la aplicaci√≥n y asegurar que cumple con altos est√°ndares de accesibilidad (A11y).
- **Detalles T√©cnicos:**
  - **UI:** Sidebar con pesta√±as, paleta "Quick Open" (‚åò+P), virtual scrolling para listas largas.
  - **Accesibilidad:** Cumplimiento de WCAG 2.1 AA. Navegaci√≥n completa por teclado, contraste de colores, atributos ARIA.
  - **Herramientas:** Lighthouse y Pa11y para la auditor√≠a de accesibilidad.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Probar la navegaci√≥n, el drag-and-drop de proyectos y el Quick Open.
  - **Accessibility Tests:** Integrar Pa11y en el pipeline de CI para detectar regresiones de accesibilidad.
- **Documentaci√≥n:**
  - Documentar las decisiones de accesibilidad en un ADR.
- **Criterios de Aceptaci√≥n:**
  - La puntuaci√≥n de Accesibilidad en Lighthouse es ‚â• 90.
  - La paleta Quick Open (‚åò+P) se abre en < 150 ms (p95).
  - El scroll en una lista virtualizada de 10,000 l√≠neas no presenta "jank" (FPS > 50).
  - El reordenamiento de proyectos mediante drag-and-drop persiste el orden.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (E2E, accessibility) pasan.
  - Reportes de Lighthouse y Pa11y analizados y los problemas cr√≠ticos resueltos.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                     |                      |                                                                                                                                     |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- | -------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                          | Complejidad Estimada | Entregable Verificable                                                                                                              |
| R3.WP1-T21-ST1                   | Implementar el componente Sidebar con pesta√±as y la funcionalidad de reordenamiento de proyectos con drag-and-drop. | 5                    | Test Cypress que arrastra un proyecto a una nueva posici√≥n en la lista y verifica que el orden se persiste tras recargar la p√°gina. |
| R3.WP1-T21-ST2                   | Implementar la paleta "Quick Open" (‚åò+P) y el virtual-scroll para listas largas.                                    | 4                    | Test Cypress que presiona ‚åò+P, busca un documento y navega a √©l. El scroll en una lista de 1000 items es fluido.                    |
| R3.WP1-T21-ST3                   | Realizar una auditor√≠a de accesibilidad (A11y) con Lighthouse/Pa11y y corregir los problemas de mayor prioridad.    | 3                    | Reporte de Lighthouse con una puntuaci√≥n de Accesibilidad ‚â• 90.                                                                     |

---

### **Tarea T-22: Delete & Restore (Logical)**

- **ID de Tarea:** T-22
- **T√≠tulo:** Delete & Restore (Logical)
- **Estado:** Pendiente
- **Dependencias:** T-37
- **Prioridad:** Alta
- **Release Target:** Release 4
- **Descripci√≥n:** Implementar la funcionalidad de borrado l√≥gico (mover a la papelera) y restauraci√≥n de documentos. Los documentos borrados l√≥gicamente deben ser recuperables durante un per√≠odo de tiempo configurable.
- **Detalles T√©cnicos:**
  - **Backend:** Usar un campo deleted_at (soft delete) en el modelo del documento. Endpoints DELETE /docs/{id} y POST /docs/{id}/restore.
  - **Frontend:** Mover los documentos borrados a una vista de "Papelera" desde donde se pueden restaurar.
- **Estrategia de Test:**
  - **Integration Tests:** Probar los endpoints de borrado y restauraci√≥n.
  - **E2E Tests (Cypress):** Probar el flujo completo desde la UI: borrar un documento, ir a la papelera y restaurarlo.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para los nuevos endpoints.
- **Criterios de Aceptaci√≥n:**
  - La llamada a DELETE /docs/{id} marca el documento como "deleted" en la base de datos.
  - La llamada a /docs/{id}/restore recupera el documento si se realiza dentro del per√≠odo de retenci√≥n.
  - Despu√©s del per√≠odo de retenci√≥n, el documento es un candidato para la purga por el job de T-36.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                                             |                      |                                                                                                           |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                  | Complejidad Estimada | Entregable Verificable                                                                                    |
| R4.WP1-T22-ST1                   | A√±adir el campo deleted_at al modelo de datos del documento y modificar las consultas para excluir los documentos borrados. | 3                    | Test que verifica que un documento con deleted_at no aparece en la lista principal de documentos.         |
| R4.WP1-T22-ST2                   | Implementar los endpoints de backend /docs/{id} (DELETE) y /docs/{id}/restore.                                              | 3                    | Colecci√≥n Postman que borra l√≥gicamente un documento y luego lo restaura, verificando el estado en la DB. |
| R4.WP1-T22-ST3                   | Implementar los botones correspondientes en la UI y la vista de "Papelera".                                                 | 3                    | Test Cypress que mueve un documento a la papelera y luego lo restaura desde all√≠.                         |

---

### **Tarea T-23: Health-check API**

- **ID de Tarea:** T-23
- **T√≠tulo:** Health-check API
- **Estado:** Completado
- **Dependencias:** T-01
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Exponer un endpoint de health-check que verifique el estado de la aplicaci√≥n y sus dependencias cr√≠ticas (base de datos, vector-store, API de OpenAI).
- **Detalles T√©cnicos:**
  - **Endpoint:** GET /healthz.
  - **Respuesta:** JSON con un estado general (ok o degraded) y el estado de cada dependencia.
- **Estrategia de Test:**
  - **Integration Tests:** Probar el endpoint en diferentes escenarios (todo funcionando, una dependencia ca√≠da) y verificar la respuesta.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el endpoint /healthz.
- **Criterios de Aceptaci√≥n:**
  - El endpoint responde con HTTP 200 y un p95 de latencia < 200 ms.
  - El endpoint retorna un estado degraded si alguna de sus dependencias clave falla.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests de integraci√≥n pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 5)**

|                                  |                                                                                             |                      |                                                                                                                |
| -------------------------------- | ------------------------------------------------------------------------------------------- | -------------------- | -------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                  | Complejidad Estimada | Entregable Verificable                                                                                         |
| R0.WP1-T23-ST1                   | Implementar el endpoint /healthz que devuelve un estado b√°sico "ok".                        | 2                    | Endpoint /healthz responde con HTTP 200 y {"status": "ok"}.                                                    |
| R0.WP1-T23-ST2                   | A√±adir las verificaciones de conectividad a la base de datos, vector-store y API de OpenAI. | 3                    | Test de integraci√≥n que simula una ca√≠da de la DB y verifica que /healthz responde con {"status": "degraded"}. |

---

### **Tarea T-24: Consentimiento Expl√≠cito**

- **ID de Tarea:** T-24
- **T√≠tulo:** Consentimiento Expl√≠cito
- **Estado:** Pendiente
- **Dependencias:** T-04
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 1
- **Descripci√≥n:** Implementar un mecanismo de consentimiento expl√≠cito del usuario antes de enviar sus datos a servicios de IA externos. El consentimiento debe ser registrado de forma inmutable.
- **Detalles T√©cnicos:**
  - **UI:** Checkbox en la interfaz de subida de archivos.
  - **Backend:** Registrar el evento de consentimiento en el log de auditor√≠a de T-13. La l√≥gica de negocio debe impedir la llamada a la IA si no hay consentimiento.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Probar que el bot√≥n de "Upload" est√° deshabilitado hasta que se marca el checkbox. Probar que si no se da el consentimiento, las funcionalidades de IA no se ejecutan.
- **Documentaci√≥n:**
  - Documentar el flujo de consentimiento.
- **Criterios de Aceptaci√≥n:**
  - Sin marcar el checkbox, los botones "Upload" y "Generate context" est√°n deshabilitados.
  - El acto de dar consentimiento se registra en el log de auditor√≠a inmutable.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests E2E pasan.
  - El flujo ha sido revisado y aprobado desde una perspectiva de compliance.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 7)**

|                                  |                                                                                                               |                      |                                                                                                            |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                    | Complejidad Estimada | Entregable Verificable                                                                                     |
| R1.WP1-T24-ST1                   | A√±adir el checkbox de consentimiento en la UI de subida de archivos.                                          | 2                    | El checkbox es visible en la UI y el bot√≥n de "Upload" est√° deshabilitado por defecto.                     |
| R1.WP1-T24-ST2                   | Implementar la l√≥gica de frontend para habilitar/deshabilitar los botones seg√∫n el estado del checkbox.       | 2                    | Test Cypress que verifica que el bot√≥n "Upload" se habilita al marcar el checkbox.                         |
| R1.WP1-T24-ST3                   | Implementar la l√≥gica de backend para registrar el consentimiento en el log de auditor√≠a al subir un archivo. | 3                    | Al subir un archivo, se crea una entrada en el log de auditor√≠a registrando el consentimiento del usuario. |

---

### **Tarea T-25: Dashboard Costes & Costo por Documento**

- **ID de Tarea:** T-25
- **T√≠tulo:** Dashboard Costes & Costo por Documento
- **Estado:** Pendiente
- **Dependencias:** T-14
- **Prioridad:** Alta
- **Release Target:** Release 5
- **Descripci√≥n:** Extender la soluci√≥n de observabilidad para incluir la monitorizaci√≥n de costes. El objetivo es calcular y visualizar el coste de la API de IA por documento, por d√≠a y por modelo, y alertar sobre desviaciones.
- **Detalles T√©cnicos:**
  - **Backend:** Registrar el consumo de tokens por cada llamada a la IA, asoci√°ndolo a un documento.
  - **C√°lculo:** Un servicio o script que traduce el consumo de tokens a coste en USD, usando los precios de la API de OpenAI.
  - **Visualizaci√≥n:** A√±adir nuevos paneles al dashboard de Grafana de T-14.
- **Estrategia de Test:**
  - **Unit Tests:** Para la l√≥gica de c√°lculo de costes.
  - **Integration Tests:** Verificar que las m√©tricas de coste se exportan correctamente a Prometheus.
- **Documentaci√≥n:**
  - Documentar c√≥mo se calculan las m√©tricas de coste.
- **Criterios de Aceptaci√≥n:**
  - La m√©trica de coste por documento (USD/doc) se calcula y tiene una desviaci√≥n < 5% en comparaci√≥n con la Usage API de OpenAI.
  - El dashboard muestra el total de tokens por documento, el coste por d√≠a/modelo y el coste por documento.
  - Se han configurado alertas para el coste por documento y para desviaciones > 5%.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration) pasan.
  - El dashboard de costes est√° funcional y validado.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 12)**

|                                  |                                                                                                                                 |                      |                                                                                                          |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------------- | -------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                      | Complejidad Estimada | Entregable Verificable                                                                                   |
| R5.WP1-T25-ST1                   | Instrumentar el c√≥digo para registrar el n√∫mero de tokens utilizados por cada llamada a la API de IA, asoci√°ndolo al documento. | 5                    | Tras generar un documento, la DB contiene un registro del total de tokens consumidos para ese documento. |
| R5.WP1-T25-ST2                   | Crear el servicio o script que calcula el coste en USD basado en los tokens y el modelo utilizado.                              | 4                    | Test unitario que, dado un n√∫mero de tokens y un modelo, calcula el coste en USD correctamente.          |
| R5.WP1-T25-ST3                   | A√±adir las nuevas m√©tricas y alertas de coste al dashboard de Grafana.                                                          | 3                    | Screenshot del dashboard de Grafana mostrando el coste por documento y el coste diario.                  |

---

### **Tarea T-26: Storage Quota**

- **ID de Tarea:** T-26
- **T√≠tulo:** Storage Quota
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Media
- **Release Target:** Release 5
- **Descripci√≥n:** Implementar una cuota de almacenamiento global para prevenir el uso excesivo de disco. Si se supera la cuota, el sistema debe rechazar nuevas subidas de archivos.
- **Detalles T√©cnicos:**
  - **Backend:** Un servicio que monitoriza el uso total del almacenamiento (base de datos + vector-store + archivos).
  - **Validaci√≥n:** El endpoint de subida debe verificar el uso actual antes de aceptar un nuevo archivo.
  - **UI:** Mostrar una alerta en el panel de settings cuando se acerca al l√≠mite.
- **Estrategia de Test:**
  - **Integration Tests:** Probar que una subida que superar√≠a la cuota es rechazada con un HTTP 507 (Insufficient Storage).
  - **E2E Tests (Cypress):** Verificar que la alerta en la UI se muestra correctamente.
- **Documentaci√≥n:**
  - Documentar el c√≥digo de error 507 en la API.
- **Criterios de Aceptaci√≥n:**
  - Una subida de archivo que har√≠a que el almacenamiento total superara los 50 GB es rechazada con un HTTP 507.
  - Una alerta es visible en el panel de Settings cuando el uso supera el 90% de la cuota.

- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 7)**

|                                  |                                                                                                                    |                      |                                                                                                                                       |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------ | -------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                         | Complejidad Estimada | Entregable Verificable                                                                                                                |
| R5.WP2-T26-ST1                   | Implementar un servicio que monitorice el uso total de almacenamiento y lo exponga como una m√©trica de Prometheus. | 3                    | Endpoint de m√©tricas que expone el uso actual del almacenamiento.                                                                     |
| R5.WP2-T26-ST2                   | A√±adir la validaci√≥n en el endpoint de subida para rechazar peticiones si se supera la cuota de 50 GB.             | 2                    | Test de integraci√≥n que intenta subir un archivo superando la cuota y recibe un HTTP 507.                                             |
| R5.WP2-T26-ST3                   | A√±adir una alerta visual en el panel de settings de la UI cuando se acerca al l√≠mite.                              | 2                    | Test Cypress que verifica que la alerta es visible en el panel de Settings cuando el uso de almacenamiento supera el 90% de la cuota. |

---

### **Tarea T-27: Uptime Monitoring**

- **ID de Tarea:** T-27
- **T√≠tulo:** Uptime Monitoring
- **Estado:** Pendiente
- **Dependencias:** T-14
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Configurar un sistema de monitorizaci√≥n externo para medir el uptime del servicio y alertar en caso de ca√≠da, cumpliendo con los SLAs de disponibilidad.
- **Detalles T√©cnicos:**
  - **Herramientas:** Sonda de Prometheus (Blackbox Exporter) para verificar el endpoint /healthz de T-23.
  - **Visualizaci√≥n:** Dashboard en Grafana para el uptime.
  - **Alertas:** Alertmanager para enviar notificaciones.
- **Estrategia de Test:**
  - **Integration Tests:** Simular una ca√≠da del servicio y verificar que se recibe una alerta en el canal configurado (ej. Slack, email).
- **Documentaci√≥n:**
  - Documentar el dashboard de uptime y las reglas de alerta.
- **Criterios de Aceptaci√≥n:**
  - Un informe mensual de Grafana muestra un uptime ‚â• 99%.
  - Una incidencia que causa una ca√≠da del servicio es reportada (MTTR) en ‚â§ 2 horas.
- **Definici√≥n de Hecho (DoD):**
  - Configuraci√≥n revisada y aprobada.
  - El test de alerta funciona correctamente.
  - El dashboard de uptime est√° funcional.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 7)**

|                                  |                                                                                                                         |                      |                                                                                                   |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                              | Complejidad Estimada | Entregable Verificable                                                                            |
| R6.WP1-T27-ST1                   | Configurar una sonda de Prometheus (ej. Blackbox Exporter) para verificar la disponibilidad del endpoint /healthz.      | 3                    | M√©trica probe_success es visible en Prometheus.                                                   |
| R6.WP1-T27-ST2                   | Crear un dashboard en Grafana para visualizar el uptime hist√≥rico y el estado actual.                                   | 2                    | Screenshot del dashboard de uptime.                                                               |
| R6.WP1-T27-ST3                   | Configurar alertas en Alertmanager para notificar (ej. por Slack/email) si el servicio est√° ca√≠do por m√°s de X minutos. | 2                    | Regla de alerta configurada. Test que simula una ca√≠da y verifica que se recibe una notificaci√≥n. |

---

### **Tarea T-28: Token Budget Guard**

- **ID de Tarea:** T-28
- **T√≠tulo:** Token Budget Guard
- **Estado:** Pendiente
- **Dependencias:** T-07
- **Prioridad:** Alta
- **Release Target:** Release 3
- **Descripci√≥n:** Implementar una salvaguarda para evitar enviar peticiones a la API de IA que excedan el l√≠mite de tokens del modelo. Esto previene errores y costes inesperados.
- **Detalles T√©cnicos:**
  - **Frontend:** Librer√≠a de tokenizaci√≥n (ej. tiktoken) para contar los tokens en el cliente y mostrar una advertencia visual.
  - **Backend:** Validar el tama√±o del prompt en el servidor antes de enviarlo a la API de IA.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Probar que la advertencia en la UI aparece al 90% del l√≠mite.
  - **Integration Tests:** Probar que el backend rechaza una petici√≥n que supera el l√≠mite con un HTTP 413 (Payload Too Large).
- **Documentaci√≥n:**
  - Documentar el c√≥digo de error 413 en la API.
- **Criterios de Aceptaci√≥n:**
  - Al alcanzar el 90% del presupuesto de tokens (8,100 tokens), se despliega una advertencia visual en la UI.
  - Un intento de enviar una petici√≥n que exceda los 9,000 tokens es rechazado con un HTTP 413 y un mensaje claro.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (E2E, integration) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                                   |                      |                                                                                                                              |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                        | Complejidad Estimada | Entregable Verificable                                                                                                       |
| R3.WP2-T28-ST1                   | Implementar la l√≥gica en el frontend para contar los tokens del contexto y mostrar una advertencia visual al 90%. | 4                    | Test Cypress que a√±ade texto hasta superar el 90% del l√≠mite y verifica que aparece la advertencia.                          |
| R3.WP2-T28-ST2                   | Implementar la validaci√≥n en el backend para rechazar peticiones que superen el l√≠mite de 9000 tokens.            | 3                    | Test de API que env√≠a una petici√≥n con m√°s de 9000 tokens y recibe un HTTP 413.                                              |
| R3.WP2-T28-ST3                   | Asegurar que el mensaje de error es claro y se muestra correctamente en la UI.                                    | 2                    | Test Cypress que intenta enviar una petici√≥n demasiado grande y verifica que se muestra un mensaje de error √∫til al usuario. |

---

### **Tarea T-29: Restore-Verifier**

- **ID de Tarea:** T-29
- **T√≠tulo:** Restore-Verifier
- **Estado:** Pendiente
- **Dependencias:** T-15
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Crear un job automatizado que verifique peri√≥dicamente la integridad y la viabilidad de los backups. Este proceso simula una restauraci√≥n y valida los datos para garantizar que los backups son fiables.
- **Detalles T√©cnicos:**
  - **Automatizaci√≥n:** Job de CI/CD (ej. GitHub Actions) programado para ejecutarse semanalmente.
  - **Script:** Script restore --verify que utiliza el script de restauraci√≥n de T-15 en un entorno temporal y aislado.
  - **Validaci√≥n:** Comparaci√≥n de checksums (hashes) de los datos clave (ej. una selecci√≥n de registros de la DB) antes del backup y despu√©s de la restauraci√≥n.
- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma un test automatizado de la tarea T-15.
- **Documentaci√≥n:**
  - Documentar el proceso de verificaci√≥n en el runbook de operaciones de T-15.
- **Criterios de Aceptaci√≥n:**
  - El job se ejecuta semanalmente de forma programada.
  - El hash de los datos restaurados se compara con el hash de los datos originales; una divergencia dispara una alerta cr√≠tica (email/Slack) al equipo de operaciones.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (script, config CI) revisado y aprobado.
  - El job de CI se ejecuta correctamente y es capaz de detectar una divergencia en un escenario de prueba.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 7)**

|                                  |                                                                                                                               |                      |                                                                                                               |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                    | Complejidad Estimada | Entregable Verificable                                                                                        |
| R6.WP1-T29-ST1                   | Desarrollar la l√≥gica del script restore --verify que orquesta la restauraci√≥n en un entorno temporal.                        | 4                    | El script se ejecuta sin errores en un entorno de CI, restaurando el √∫ltimo backup disponible.                |
| R6.WP1-T29-ST2                   | Implementar la l√≥gica de validaci√≥n de checksum del contenido restaurado contra una fuente de verdad (hashes pre-calculados). | 3                    | El script compara los hashes y devuelve un c√≥digo de salida 0 si coinciden, y 1 si no, disparando una alerta. |

---

### **Tarea T-30: Rewrite-Latency Test**

- **ID de Tarea:** T-30
- **T√≠tulo:** Rewrite-Latency Test
- **Estado:** Pendiente
- **Dependencias:** T-08
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Crear un test de rendimiento espec√≠fico para el endpoint /rewrite, ya que es una de las interacciones de IA m√°s frecuentes y su latencia impacta directamente en la experiencia de usuario.
- **Detalles T√©cnicos:**
  - **Herramientas:** JMeter o Locust.
  - **Escenario:** Simular 50 usuarios concurrentes que env√≠an peticiones al endpoint /rewrite con un payload de 100 tokens.
- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma una tarea de testing de rendimiento.
- **Documentaci√≥n:**
  - Incluir este test en la documentaci√≥n de benchmarks del proyecto.
- **Criterios de Aceptaci√≥n:**
  - La latencia p95 del endpoint /rewrite es ‚â§ 2 segundos bajo una carga de 50 usuarios concurrentes.
- **Definici√≥n de Hecho (DoD):**
  - Script de test revisado y aprobado.
  - El reporte de JMeter/Locust se ha generado y confirma que se cumple el criterio de aceptaci√≥n.
  - El test est√° integrado en el pipeline de CI de rendimiento.
  - **Acta de Certificaci√≥n del Ciclo de KPI de Rendimiento (seg√∫n plantilla de T-17) firmada por el Tech Lead.**
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 8)**

|                                  |                                                                                                |                      |                                                                           |
| -------------------------------- | ---------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                     | Complejidad Estimada | Entregable Verificable                                                    |
| R6.WP3-T30-ST1                   | Desarrollar el script de Locust/JMeter para el endpoint /rewrite con un payload de 100 tokens. | 4                    | El script env√≠a peticiones al endpoint /rewrite con el payload definido.  |
| R6.WP3-T30-ST2                   | Configurar el escenario de prueba para simular 50 usuarios concurrentes y ejecutar el test.    | 2                    | Configuraci√≥n del test de carga.                                          |
| R6.WP3-T30-ST3                   | Integrar el test en CI y generar un reporte que mida la latencia p95.                          | 2                    | Reporte de Locust/JMeter que muestra que la latencia p95 es ‚â§ 2 segundos. |

---

### **Tarea T-31: Pause/Abort Flow**

- **ID de Tarea:** T-31
- **T√≠tulo:** Pause/Abort Flow
- **Estado:** Pendiente
- **Dependencias:** T-07
- **Prioridad:** Media
- **Release Target:** Release 2
- **Descripci√≥n:** Dar al usuario el control sobre el proceso de generaci√≥n de contenido, permiti√©ndole pausar, reanudar o cancelar por completo una generaci√≥n en curso.
- **Detalles T√©cnicos:**
  - **Backend:** Endpoints POST /pause y POST /resume. La l√≥gica debe manejar el estado de la tarea de generaci√≥n (ej. en Celery).
  - **Frontend:** Bot√≥n "Pause" en la Prompt Bar que, al ser presionado, muestra un modal con las opciones "Continuar" y "Cancelar".
- **Estrategia de Test:**
  - **Integration Tests:** Probar los endpoints de la API para pausar y reanudar.
  - **E2E Tests (Cypress):** Probar el flujo completo desde la UI: iniciar generaci√≥n, pausar, ver el modal, y probar las opciones de continuar y cancelar.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para los nuevos endpoints.
- **Criterios de Aceptaci√≥n:**
  - Una petici√≥n a POST /pause tiene una latencia p95 ‚â§ 150 ms.
  - El modal de confirmaci√≥n aparece en la UI en ‚â§ 200 ms tras hacer clic en "Pause".
  - La opci√≥n "Continuar" reanuda el flujo de generaci√≥n, y "Cancelar" lo detiene permanentemente.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 10)**

|                                  |                                                                                                                     |                      |                                                                                                       |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- | -------------------- | ----------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                          | Complejidad Estimada | Entregable Verificable                                                                                |
| R2.WP1-T31-ST1                   | Implementar los endpoints de API /pause y /resume en el backend para controlar el estado de la tarea de generaci√≥n. | 4                    | Colecci√≥n Postman que prueba los endpoints y verifica que el estado de la tarea de generaci√≥n cambia. |
| R2.WP1-T31-ST2                   | A√±adir el bot√≥n "Pause" en la Prompt Bar de la UI.                                                                  | 3                    | El bot√≥n es visible durante la generaci√≥n de contenido.                                               |
| R2.WP1-T31-ST3                   | Implementar el modal de confirmaci√≥n con las opciones "Continuar" y "Cancelar" y su l√≥gica correspondiente.         | 3                    | Test Cypress que pausa la generaci√≥n, hace clic en "Cancelar" y verifica que el flujo se detiene.     |

---

### **Tarea T-32: Template Management**

- **ID de Tarea:** T-32
- **T√≠tulo:** Template Management
- **Estado:** Pendiente
- **Dependencias:** T-01
- **Prioridad:** Alta
- **Release Target:** Release 3
- **Descripci√≥n:** Crear una interfaz de gesti√≥n completa (CRUD) para las plantillas de prompts. Los usuarios administradores podr√°n crear, listar, editar y eliminar plantillas que luego estar√°n disponibles para todos los usuarios.
- **Detalles T√©cnicos:**
  - **Backend:** API REST (/templates) para el CRUD de plantillas, con persistencia en la base de datos.
  - **Frontend:** Interfaz en la secci√≥n de "Settings" del panel de administraci√≥n.
  - **DB:** Tabla templates con migraciones gestionadas por Alembic o similar.
- **Estrategia de Test:**
  - **Integration Tests:** Cobertura completa de la API /templates.
  - **E2E Tests (Cypress):** Probar el flujo CRUD completo desde la UI del panel de administraci√≥n.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para los endpoints de /templates.
- **Criterios de Aceptaci√≥n:**
  - El CRUD de plantillas opera con √©xito (respuestas 2xx) y los cambios se reflejan en la base de datos.
  - El dropdown de selecci√≥n de plantillas de T-18 lista las plantillas creadas aqu√≠.
  - La API valida los inputs (ej. nombre de plantilla no vac√≠o) y retorna errores 4xx claros.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - Documentaci√≥n de API y scripts de migraci√≥n completados.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                            |                      |                                                                                          |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                 | Complejidad Estimada | Entregable Verificable                                                                   |
| R3.WP2-T32-ST1                   | Implementar los endpoints REST para el CRUD de plantillas (/templates) y las migraciones de DB.            | 4                    | Colecci√≥n Postman que prueba el CRUD completo de plantillas. Script de migraci√≥n existe. |
| R3.WP2-T32-ST2                   | Desarrollar la UI en la secci√≥n de "Settings" (usando el esqueleto de T-44) para gestionar las plantillas. | 5                    | Test Cypress donde un usuario crea, edita y elimina una plantilla a trav√©s de la UI.     |

---

### **Tarea T-33: Draft-Quality Test**

- **ID de Tarea:** T-33
- **T√≠tulo:** Draft-Quality Test
- **Estado:** Pendiente
- **Dependencias:** T-06
- **Prioridad:** Alta
- **Release Target:** Release 2
- **Descripci√≥n:** Crear un test harness automatizado para evaluar la calidad sem√°ntica y la cobertura del borrador inicial generado por el sistema, compar√°ndolo contra un dataset de referencia.
- **Detalles T√©cnicos:**
  - **M√©trica:** ROUGE-L para medir la similitud sem√°ntica.
  - **Dataset:** Un conjunto de 10 documentos de referencia con sus borradores "golden" esperados.
  - **Automatizaci√≥n:** Integrar el test en el pipeline de CI para detectar regresiones de calidad.
- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma una tarea de testing de calidad.
- **Documentaci√≥n:**
  - Documentar el dataset y el proceso de evaluaci√≥n.
- **Criterios de Aceptaci√≥n:**
  - El score ROUGE-L es ‚â• 0.8 en el borrador inicial (p95) en comparaci√≥n con el dataset de referencia.
  - La latencia para generar un borrador completo es ‚â§ 8 minutos (p95).
  - El job de CI falla si el score ROUGE-L es < 0.8 o la latencia es > 8 minutos.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (test harness, dataset) revisado y aprobado.
  - El job de CI est√° configurado y pasa con la implementaci√≥n actual.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 13)**

|                                  |                                                                                                                   |                      |                                                                                       |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                        | Complejidad Estimada | Entregable Verificable                                                                |
| R2.WP2-T33-ST1                   | Crear un dataset de referencia con 10 documentos fuente y sus borradores "golden" esperados.                      | 4                    | El dataset existe en el repositorio en un formato estructurado (ej. JSON).            |
| R2.WP2-T33-ST2                   | Desarrollar el test harness que genera borradores para el dataset y calcula el score ROUGE-L contra los "golden". | 6                    | El script se ejecuta y produce un reporte con los scores ROUGE-L para cada documento. |
| R2.WP2-T33-ST3                   | Integrar el test en el pipeline de CI para que falle si el score o la latencia no cumplen los umbrales.           | 3                    | El job de CI falla si el ROUGE-L p95 es < 0.8 o la latencia p95 es > 8 min.           |

---

### **Tarea T-34: Usability Testing**

- **ID de Tarea:** T-34
- **T√≠tulo:** Usability Testing
- **Estado:** Pendiente
- **Dependencias:** T-10, T-21
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 6
- **Descripci√≥n:** Realizar una ronda de pruebas de usabilidad formales con usuarios reales para evaluar la experiencia de usuario del producto y recopilar feedback para mejoras finales.
- **Detalles T√©cnicos:**
  - **Metodolog√≠a:** Pruebas de usuario moderadas.
  - **Participantes:** 5 usuarios del perfil objetivo.
  - **M√©trica:** System Usability Scale (SUS).
  - **Guion:** Definir un guion con tareas clave (ej. subir un archivo, generar un borrador, editar una secci√≥n, exportar).
- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma una tarea de testing de usabilidad.
- **Documentaci√≥n:**
  - Plan de pruebas de usabilidad.
  - Informe final de usabilidad con los hallazgos, el score SUS y las recomendaciones.
- **Criterios de Aceptaci√≥n:**
  - El score SUS promedio de la prueba es ‚â• 80.
  - Todos los usuarios participantes son capaces de completar el guion de tareas sin bloqueos cr√≠ticos.
  - Los hallazgos est√°n documentados y se han creado propuestas de mejora para ser abordadas en T-40.
- **Definici√≥n de Hecho (DoD):**
  - Plan de pruebas aprobado.
  - Sesiones de prueba completadas y grabadas.
  - Informe de usabilidad finalizado y revisado por el equipo.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 11)**

|                                  |                                                                                                                            |                      |                                                                                                      |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                 | Complejidad Estimada | Entregable Verificable                                                                               |
| R6.WP3-T34-ST1                   | Dise√±ar el plan de pruebas de usabilidad: reclutar 5 usuarios, definir el guion de tareas y preparar el entorno.           | 3                    | Documento del plan de pruebas aprobado por el Product Owner.                                         |
| R6.WP3-T34-ST2                   | Ejecutar las sesiones de prueba piloto, grabar las sesiones (con consentimiento) y administrar la encuesta SUS.            | 5                    | Grabaciones de las 5 sesiones y los resultados de las encuestas SUS recopilados.                     |
| R6.WP3-T34-ST3                   | Analizar los resultados, calcular el puntaje SUS promedio y redactar un informe con los hallazgos clave y recomendaciones. | 3                    | Informe de usabilidad finalizado, incluyendo el puntaje SUS y una lista de 3-5 mejoras recomendadas. |

---

### **Tarea T-35: GDPR Erasure on Demand**

- **ID de Tarea:** T-35
- **T√≠tulo:** GDPR Erasure on Demand
- **Estado:** Pendiente
- **Dependencias:** T-13, T-22
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 5
- **Descripci√≥n:** Implementar la funcionalidad que permite a un usuario solicitar el borrado definitivo de un documento, en cumplimiento con el "derecho al olvido" del GDPR.
- **Detalles T√©cnicos:**
  - **Backend:** Endpoint DELETE /docs/{id}/erase que marca un documento para purga inmediata.
  - **Frontend:** Bot√≥n "Borrar definitivamente" en la UI (ej. en la papelera) con un modal de confirmaci√≥n muy claro sobre la irreversibilidad de la acci√≥n.
  - **Auditor√≠a:** La solicitud de borrado debe registrarse en el log WORM de T-13.
- **Estrategia de Test:**
  - **Integration Tests:** Probar el endpoint /erase.
  - **E2E Tests:** Probar el ciclo completo: borrar l√≥gicamente (T-22), ir a la papelera, borrar definitivamente y verificar que el documento ya no es accesible.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el nuevo endpoint.
- **Criterios de Aceptaci√≥n:**
  - Una llamada a DELETE /docs/{id}/erase devuelve un HTTP 204 tras la confirmaci√≥n del usuario.
  - Se crea una entrada en el Audit Log WORM con el usuario, doc-ID y timestamp en ‚â§ 5 segundos.
  - El documento se marca para ser purgado por el job de T-36.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (integration, E2E) pasan.
  - El flujo ha sido validado desde una perspectiva de compliance.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 10)**

|                                  |                                                                                          |                      |                                                                                                       |
| -------------------------------- | ---------------------------------------------------------------------------------------- | -------------------- | ----------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                               | Complejidad Estimada | Entregable Verificable                                                                                |
| R5.WP2-T35-ST1                   | Implementar el endpoint DELETE /docs/{id}/erase que marca un documento para purga.       | 4                    | Colecci√≥n Postman que prueba el endpoint y verifica que el documento se marca correctamente en la DB. |
| R5.WP2-T35-ST2                   | A√±adir el bot√≥n "Borrar definitivamente" en la UI y el flujo de confirmaci√≥n.            | 3                    | Test Cypress que borra un documento permanentemente y verifica que desaparece de la UI.               |
| R5.WP2-T35-ST3                   | Asegurar que la acci√≥n de borrado se registra correctamente en el log WORM de auditor√≠a. | 3                    | Test que borra un documento y verifica que se crea la entrada correspondiente en el log de auditor√≠a. |

---

### **Tarea T-36: GDPR Erase Purge Job**

- **ID de Tarea:** T-36
- **T√≠tulo:** GDPR Erase Purge Job
- **Estado:** Pendiente
- **Dependencias:** T-35, T-15
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 6
- **Descripci√≥n:** Crear un job automatizado que purga de forma irreversible los datos de los documentos que han sido marcados para borrado definitivo (T-35) o cuyo per√≠odo de retenci√≥n en la papelera (T-22) ha expirado. **Nota de Riesgo Cr√≠tico:** Esta tarea es de alto impacto y requiere una validaci√≥n exhaustiva. **Nota de Gesti√≥n de Riesgo:** La implementaci√≥n y revisi√≥n de esta tarea debe ser asignada a personal senior. El plan de pruebas para la purga de backups (ST3) debe ser aprobado expl√≠citamente por el Tech Lead.
- **Detalles T√©cnicos:**
  - **Automatizaci√≥n:** Cron job diario.
  - **L√≥gica:** El job debe eliminar los datos del documento de todas las ubicaciones: base de datos principal, tabla de versiones, vector-store, almacenamiento de archivos y backups.
- **Estrategia de Test:**
  - **E2E Tests:** Probar el ciclo de vida completo del borrado: crear doc -> borrar l√≥gicamente -> esperar/forzar expiraci√≥n -> ejecutar job de purga -> verificar que los datos han sido eliminados de todos los sistemas.
- **Documentaci√≥n:**
  - Documentar el proceso de purga y las ubicaciones de datos que afecta.
- **Criterios de Aceptaci√≥n:**
  - El cron job diario se ejecuta sin errores.
  - Los datos de las solicitudes de borrado con m√°s de 30 d√≠as (o marcados para borrado inmediato) son purgados de forma irrevocable.
  - Un test E2E valida el ciclo de vida completo del borrado.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (job) revisado y aprobado.
  - El test E2E del ciclo de vida del borrado pasa.
  - El proceso ha sido validado desde una perspectiva de compliance.
  - **Acta de Certificaci√≥n del Ciclo de Borrado (seg√∫n plantilla de T-17) firmada por el Tech Lead.**
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 17)**

|                                  |                                                                                                                                                                                                                                                                                       |                      |                                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                                                                                                                                                            | Complejidad Estimada | Entregable Verificable                                                                                                       |
| R6.WP1-T36-ST1                   | Implementar el cron job diario (purge_erase_requests) que identifica los documentos a purgar.                                                                                                                                                                                         | 4                    | El job se ejecuta y genera una lista de los IDs de documentos a eliminar.                                                    |
| R6.WP1-T36-ST2                   | Implementar la l√≥gica de purga de sistemas en vivo (Base de Datos, Vector-Store, Almacenamiento de Archivos).                                                                                                                                                                         | 4                    | Test de integraci√≥n que verifica que, tras ejecutar la purga, los datos del documento ya no existen en los sistemas en vivo. |
| R6.WP1-T36-ST3                   | (Alto Riesgo) Dise√±ar e implementar script de purga de datos espec√≠ficos de los backups encriptados. **Nota de Riesgo:** Esta es la subtarea de mayor riesgo del proyecto. Su implementaci√≥n debe ser extremadamente cuidadosa y su plan de pruebas, riguroso y formalmente aprobado. | 6                    | Test que valida que un documento purgado no puede ser restaurado desde un backup posterior a la purga.                       | l   |
| R6.WP1-T36-ST4                   | Validar el ciclo de vida de borrado E2E (T-22 -> T-35 -> T-36) en un entorno de pruebas.                                                                                                                                                                                              | 3                    | Reporte de test E2E que confirma que el ciclo completo de borrado funciona como se espera.                                   |

---

### **Tarea T-37: Admin Panel: Add User & System Mgmt Features**

- **ID de Tarea:** T-37
- **T√≠tulo:** Admin Panel: Add User & System Mgmt Features
- **Estado:** Pendiente
- **Dependencias:** T-02, T-44, T-04
- **Prioridad:** Alta
- **Release Target:** Release 4
- **Descripci√≥n:** Extender el panel de administraci√≥n existente (T-44) para permitir a los usuarios con rol admin gestionar usuarios y configuraciones clave del sistema.
- **Detalles T√©cnicos:**
  - **UI:** Nueva secci√≥n en la aplicaci√≥n, visible solo para administradores.
  - **Funcionalidades:**
    1. CRUD de usuarios.
    2. Ver estado del vector-store y disparar re-indexaci√≥n.
    3. Configurar la ventana de retenci√≥n para el borrado l√≥gico.
    4. Seleccionar el modelo de IA por defecto para la generaci√≥n.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Probar cada una de las funcionalidades del panel de administraci√≥n desde la perspectiva de un usuario admin.
- **Documentaci√≥n:**
  - Documentar las capacidades del panel de administraci√≥n.
- **Criterios de Aceptaci√≥n:**
  - El CRUD de usuarios se refleja inmediatamente en el sistema (ej. un usuario desactivado no puede iniciar sesi√≥n).
  - El panel muestra el estado del vector-store y el bot√≥n de re-indexaci√≥n dispara la tarea correspondiente.
  - El sistema respeta la ventana de restauraci√≥n y el modelo de IA configurados en el panel.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests E2E del panel de administraci√≥n pasan.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                                          |                      |                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ | -------------------- | ------------------------------------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                               | Complejidad Estimada | Entregable Verificable                                                                                       |
| R4.WP2-T37-ST1                   | Implementar la UI y los endpoints API para el CRUD de usuarios (Crear, Leer, Actualizar rol, Desactivar).                | 5                    | Test Cypress donde un admin crea un nuevo usuario, cambia su rol y lo desactiva, verificando los cambios.    |
| R4.WP2-T37-ST2                   | Implementar la secci√≥n del panel para ver el estado del vector-store y un bot√≥n para disparar una re-indexaci√≥n.         | 4                    | El panel muestra "Healthy". Un clic en "Re-index" dispara una tarea as√≠ncrona y la UI muestra "Indexing...". |
| R4.WP2-T37-ST3                   | Implementar los controles en la UI para configurar la ventana de restauraci√≥n y seleccionar el modelo de IA por defecto. | 5                    | Test que cambia la ventana de restauraci√≥n y el modelo de IA, y verifica que la configuraci√≥n se aplica.     |

---

### **Tarea T-38: Implementar Sharding de Vector-Store en Producci√≥n**

- **ID de Tarea:** T-38
- **T√≠tulo:** Implementar Sharding de Vector-Store en Producci√≥n
- **Estado:** Pendiente
- **Dependencias:** T-16
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 6
- **Descripci√≥n:** Mover el PoC de sharding del vector-store de T-16 a una soluci√≥n lista para producci√≥n. Esto implica robustecer la configuraci√≥n, asegurar la persistencia, el failover y la monitorizaci√≥n.
- **Detalles T√©cnicos:**
  - **Configuraci√≥n:** Manifiestos de Kubernetes/Docker Compose para un cl√∫ster de vector-store productivo (ej. Qdrant con replicaci√≥n).
  - **Failover:** Configurar y probar el mecanismo de failover autom√°tico del vector-store.
  - **Monitorizaci√≥n:** Integrar las m√©tricas del cl√∫ster de vector-store en el dashboard de observabilidad de T-14.
- **Estrategia de Test:**
  - **Chaos Tests:** Realizar un test de caos espec√≠fico para el cl√∫ster de vector-store, eliminando nodos y verificando la recuperaci√≥n sin p√©rdida de datos.
  - **Load Tests:** Ejecutar un test de carga para demostrar el escalado horizontal del vector-store.
- **Documentaci√≥n:**
  - Actualizar el ADR de T-16 con la arquitectura de producci√≥n final.
- **Criterios de Aceptaci√≥n:**
  - Un test de carga demuestra el escalado horizontal del vector-store sin intervenci√≥n manual.
  - El failover de un nodo del vector-store se completa con un MTTR ‚â§ 15 minutos y sin p√©rdida de datos.
  - Un panel de observabilidad muestra el estado de salud y la distribuci√≥n de datos de cada shard.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (manifiestos) revisado y aprobado.
  - Los reportes de los tests de caos y carga est√°n completados y analizados.
  - El dashboard de monitorizaci√≥n est√° funcional.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 14)**

|                                  |                                                                                                                |                      |                                                                                                            |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                     | Complejidad Estimada | Entregable Verificable                                                                                     |
| R6.WP2-T38-ST1                   | Adaptar la configuraci√≥n del PoC de T-16 para un entorno de producci√≥n, incluyendo persistencia y replicaci√≥n. | 5                    | Manifiestos de Kubernetes/Docker Compose para desplegar el cl√∫ster de vector-store en modo productivo.     |
| R6.WP2-T38-ST2                   | Implementar y probar el mecanismo de failover autom√°tico.                                                      | 5                    | Reporte de un test de caos donde se elimina un nodo del vector-store y el sistema se recupera en < 15 min. |
| R6.WP2-T38-ST3                   | A√±adir monitorizaci√≥n del estado de los shards al dashboard de observabilidad.                                 | 4                    | Panel de Grafana que muestra la distribuci√≥n de datos y el estado de salud de cada shard.                  |

---

### **Tarea T-39: Implementar Pin/Favoritos en Sidebar**

- **ID de Tarea:** T-39
- **T√≠tulo:** Implementar Pin/Favoritos en Sidebar
- **Estado:** Pendiente
- **Dependencias:** T-21
- **Prioridad:** Media
- **Release Target:** Release 3
- **Descripci√≥n:** A√±adir una funcionalidad que permita a los usuarios marcar documentos como "favoritos" o "anclados" (pin), para que aparezcan en una secci√≥n dedicada en la parte superior de la barra de navegaci√≥n lateral.
- **Detalles T√©cnicos:**
  - **Backend:** Endpoint para marcar/desmarcar un documento como favorito.
  - **DB:** Tabla de uni√≥n user_favorite_documents.
  - **Frontend:** Icono de "pin" en cada item de la lista de documentos y una nueva secci√≥n "Favoritos" en la sidebar.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Probar el flujo completo: hacer clic en el icono de pin, verificar que el documento se mueve a la secci√≥n de favoritos y que el estado persiste tras recargar la p√°gina.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el nuevo endpoint.
- **Criterios de Aceptaci√≥n:**
  - Al hacer clic en el icono 'pin', el documento se mueve a la secci√≥n 'Favoritos' y el estado persiste entre sesiones.
  - La secci√≥n 'Favoritos' es la primera en la lista de navegaci√≥n de la sidebar.

- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests E2E pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 7)**

|                                  |                                                                                              |                      |                                                                                                         |
| -------------------------------- | -------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                   | Complejidad Estimada | Entregable Verificable                                                                                  |
| R3.WP1-T39-ST1                   | Modificar el modelo de datos para almacenar el estado de "favorito" por usuario y documento. | 2                    | Script de migraci√≥n de la base de datos.                                                                |
| R3.WP1-T39-ST2                   | Implementar el endpoint de API para marcar/desmarcar un documento como favorito.             | 2                    | Colecci√≥n Postman que prueba el endpoint.                                                               |
| R3.WP1-T39-ST3                   | Implementar el icono de "pin" en la UI y la secci√≥n de "Favoritos" en la sidebar.            | 3                    | Test Cypress que marca un documento como favorito y verifica que aparece en la secci√≥n correspondiente. |

---

### **Tarea T-40: Implementaci√≥n de Mejoras de Usabilidad Post-Piloto**

- **ID de Tarea:** T-40
- **T√≠tulo:** Implementaci√≥n de Mejoras de Usabilidad Post-Piloto
- **Estado:** Pendiente
- **Dependencias:** T-34
- **Prioridad:** Alta
- **Release Target:** Release 6
- **Descripci√≥n:** Abordar los hallazgos m√°s cr√≠ticos del informe de pruebas de usabilidad de T-34. Esta tarea consiste en implementar las 2-3 mejoras de mayor impacto para pulir el producto antes del lanzamiento final.
- **Detalles T√©cnicos:**
  - Depender√° de los hallazgos del informe de T-34. Podr√≠a implicar cambios en la UI, flujos de trabajo o redacci√≥n de textos.
- **Estrategia de Test:**
  - **Regression Tests (Cypress o manual):** Verificar que las mejoras implementadas funcionan como se espera y no introducen nuevas regresiones.
- **Documentaci√≥n:**
  - Actualizar el informe de usabilidad de T-34 para marcar los hallazgos abordados como "resueltos".
- **Criterios de Aceptaci√≥n:**
  - Los Pull Requests para las mejoras priorizadas son aprobados y fusionados.
  - Un test de regresi√≥n confirma que las mejoras funcionan y no introducen errores.
  - El informe de usabilidad de T-34 se actualiza para reflejar que los hallazgos han sido resueltos.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests de regresi√≥n pasan.
  - El informe de usabilidad est√° actualizado.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                        |                      |                                                                                |
| -------------------------------- | -------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                             | Complejidad Estimada | Entregable Verificable                                                         |
| R6.WP3-T40-ST1                   | Priorizar los 2-3 hallazgos de mayor impacto del informe de T-34 con el Product Owner. | 1                    | Lista de mejoras priorizadas y aprobadas.                                      |
| R6.WP3-T40-ST2                   | Implementar la primera mejora de usabilidad priorizada.                                | 4                    | Pull Request con la implementaci√≥n de la primera mejora, aprobado y fusionado. |
| R6.WP3-T40-ST3                   | Implementar la segunda/tercera mejora de usabilidad priorizada.                        | 4                    | Pull Request con la implementaci√≥n de la segunda mejora, aprobado y fusionado. |

---

### **Tarea T-41: User API Key Management**

- **ID de Tarea:** T-41
- **T√≠tulo:** User API Key Management
- **Estado:** üöß Desarrollo Completado - Listo para QA
- **Dependencias:** T-02, T-12
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Permitir a los usuarios gestionar su propia clave de API de OpenAI. La clave ser√° almacenada de forma segura y utilizada por el backend para realizar llamadas a la API de OpenAI en nombre del usuario.
- **Detalles T√©cnicos:**
  - **Endpoint:** POST /user/credentials.
  - **Seguridad:** La clave se guarda cifrada utilizando el Credential Store de T-12. Nunca se devuelve en ninguna respuesta de la API.
  - **UI:** Secci√≥n en el perfil de usuario para introducir/actualizar la clave.
- **Estrategia de Test:**
  - **Unit Tests:** Verificar que la clave se cifra correctamente.
  - **Integration Tests:** Probar el endpoint /user/credentials. Verificar que una llamada a un servicio de IA falla con 402 si no hay clave, y funciona si hay una clave v√°lida.
  - **Security Tests:** Asegurar que la clave no se puede recuperar a trav√©s de ninguna API.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para el endpoint /user/credentials.
- **Criterios de Aceptaci√≥n:**
  - El endpoint rechaza claves inv√°lidas (formato incorrecto) con un error 400.
  - Una clave v√°lida se guarda cifrada y no se expone en ninguna respuesta de la API.
  - Las llamadas a los servicios de OpenAI sin una clave configurada devuelven un error HTTP 402 (Payment Required).
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration, security) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                   |                      |                                                                                                  |
| -------------------------------- | ------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                        | Complejidad Estimada | Entregable Verificable                                                                           |
| R0.WP2-T41-ST1                   | Implementar el endpoint POST /user/credentials que valida y guarda la clave de API del usuario.   | 4                    | Colecci√≥n Postman que prueba el endpoint con una clave v√°lida (guarda) y una inv√°lida (rechaza). |
| R0.WP2-T41-ST2                   | Utilizar el Credential Store de T-12 para encriptar la clave antes de guardarla en la DB.         | 2                    | Test que verifica que la clave en la base de datos est√° encriptada.                              |
| R0.WP2-T41-ST3                   | Implementar la UI en el perfil de usuario para que pueda introducir y actualizar su clave de API. | 3                    | Test Cypress donde un usuario guarda su clave de API a trav√©s de la UI.                          |

---

### **Tarea T-42: Risk Matrix Review (Process Task)**

- **ID de Tarea:** T-42
- **T√≠tulo:** Risk Matrix Review (Process Task)
- **Estado:** Recurrente
- **Dependencias:** Fin de cada hito (R0-R6)
- **Prioridad:** Media
- **Release Target:** N/A (Proceso)
- **Descripci√≥n:** Tarea de proceso recurrente para revisar y actualizar formalmente la matriz de riesgos del proyecto al final de cada release. Esto asegura una gesti√≥n de riesgos proactiva y continua.
- **Detalles T√©cnicos:**
  - **Herramientas:** Git, sistema de gesti√≥n de proyectos (Jira, GitHub Issues).
  - **Artefacto:** PRD v2.md, secci√≥n 10.
- **Estrategia de Test:** N/A (Tarea de proceso).
- **Documentaci√≥n:**
  - El historial de commits del fichero PRD v2.md sirve como log de las revisiones.
- **Criterios de Aceptaci√≥n:**
  - La matriz de riesgos en PRD v2.md es actualizada y se realiza un commit al final de cada release.
  - Las nuevas mitigaciones identificadas se registran como nuevas tareas en el backlog del proyecto.
- **Definici√≥n de Hecho (DoD):**
  - Reuni√≥n de revisi√≥n completada.
  - Documento PRD actualizado y commiteado.
  - Nuevas tareas de mitigaci√≥n creadas.

#### **Desglose en Subtareas (Complejidad Total: 5)**

|                                  |                                                                                                          |                      |                                                                                            |
| -------------------------------- | -------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------ |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                               | Complejidad Estimada | Entregable Verificable                                                                     |
| R<X>.POST-T42-ST1                | Convocar y facilitar la sesi√≥n de revisi√≥n de la matriz de riesgos con el Product Owner y el Tech Lead.  | 2                    | Minuta de la reuni√≥n con los puntos discutidos y decisiones tomadas.                       |
| R<X>.POST-T42-ST2                | Actualizar el fichero PRD v2.md con los cambios en la matriz de riesgos y realizar el commit.            | 2                    | Commit en el repositorio con el mensaje "docs(prd): Update risk matrix after R<X> review". |
| R<X>.POST-T42-ST3                | Crear/actualizar tareas en el backlog del proyecto para las nuevas acciones de mitigaci√≥n identificadas. | 1                    | Enlaces a las nuevas tareas creadas en el sistema de gesti√≥n de proyectos.                 |

---

### **Tarea T-43: Implementar Escaneo de Dependencias**

- **ID de Tarea:** T-43
- **T√≠tulo:** Implementar Escaneo de Dependencias
- **Estado:** Completado
- **Dependencias:** T-01
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Integrar herramientas de An√°lisis de Composici√≥n de Software (SCA) en el pipeline de CI para detectar y prevenir autom√°ticamente vulnerabilidades conocidas (CVEs) y conflictos de licencia en las dependencias de c√≥digo abierto del proyecto.
- **Detalles T√©cnicos:**
  - **Herramientas:** pip-audit, yarn audit, Dependabot, Snyk (o similar).
  - **Integraci√≥n:** Job en el pipeline qa-gate de GitHub Actions.
  - **Pol√≠tica:** Definir umbrales de severidad (ej. CRITICAL, HIGH) que bloqueen el build.
- **Estrategia de Test:**
  - **Integration Tests:** Introducir una dependencia con una vulnerabilidad conocida en una rama de prueba y verificar que el pipeline falla.
- **Documentaci√≥n:**
  - Documentar la pol√≠tica de gesti√≥n de vulnerabilidades en CONTRIBUTING.md.
- **Criterios de Aceptaci√≥n:**
  - El pipeline de CI integra escaneos de vulnerabilidades y licencias.
  - El job qa-gate falla si se detecta una vulnerabilidad de severidad CRITICAL o HIGH.
  - Un reporte de licencias es generado como artefacto de CI.
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (configuraci√≥n de CI) revisado y aprobado.
  - El pipeline es capaz de detectar y bloquear una vulnerabilidad de prueba.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                                       |                      |                                                                                    |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                            | Complejidad Estimada | Entregable Verificable                                                             |
| R0.WP1-T43-ST1                   | Integrar herramientas de escaneo de vulnerabilidades (ej. pip-audit, yarn audit) en el pipeline de CI.                 | 4                    | El pipeline de CI ejecuta los escaneos y reporta las vulnerabilidades encontradas. |
| R0.WP1-T43-ST2                   | Establecer y aplicar una pol√≠tica de gesti√≥n de vulnerabilidades que falle el build para severidades CRITICAL o HIGH. | 3                    | Un PR con una dependencia vulnerable es bloqueado por el pipeline.                 |
| R0.WP1-T43-ST3                   | Implementar un escaneo de licencias de dependencias para generar un reporte de compatibilidad.                        | 2                    | El pipeline de CI genera un artefacto con el reporte de licencias.                 |

---

### **Tarea T-44: Admin Panel Skeleton & Config Store**

- **ID de Tarea:** T-44
- **T√≠tulo:** Admin Panel Skeleton & Config Store
- **Estado:** üöß Desarrollo Completado - Listo para QA
- **Dependencias:** T-02
- **Prioridad:** Cr√≠tica
- **Release Target:** Release 0
- **Descripci√≥n:** Crear la estructura fundamental para todas las futuras funcionalidades de administraci√≥n. Esto incluye el layout de UI base para la secci√≥n "Settings" y un servicio de configuraci√≥n gen√©rico en el backend para persistir ajustes del sistema.
- **Detalles T√©cnicos:**
  - **UI:** Componente React para el layout de la secci√≥n /settings, accesible solo para roles de admin.
  - **Backend:** API REST (GET /config, POST /config) para gestionar una tabla de configuraci√≥n de tipo clave-valor.
  - **DB:** Modelo y migraci√≥n para la tabla system_configurations.
- **Estrategia de Test:**
  - **E2E Tests (Cypress):** Verificar que la ruta /settings es accesible para un admin y denegada para un editor.
  - **Integration Tests:** Probar el CRUD de la API de configuraci√≥n.
- **Documentaci√≥n:**
  - Actualizar OpenAPI para los endpoints /config.
- **Criterios de Aceptaci√≥n:**
  - La ruta /settings es accesible para roles de admin y muestra un layout vac√≠o.
  - La API /config permite leer y escribir configuraciones clave-valor.
  - La UI del panel es un esqueleto listo para ser poblado por tareas dependientes (T-03, T-32, T-37).
- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (E2E, integration) pasan.
  - Documentaci√≥n de API completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

|                                  |                                                                                                           |                      |                                                                                             |
| -------------------------------- | --------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------- |
| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                | Complejidad Estimada | Entregable Verificable                                                                      |
| ‚úÖ R0.WP2-T44-ST1 | Implementar el modelo de datos y la API REST para el servicio de configuraci√≥n clave-valor.               | 4                    | Colecci√≥n Postman que prueba el CRUD de la API /config.                                     |
| R0.WP2-T44-ST2                   | Crear el componente de UI base para el panel de "Settings" y proteger la ruta /settings por rol de admin. | 5                    | Test Cypress donde un admin accede a /settings y un editor recibe un error 403/redirecci√≥n. |

---

### **Tarea T-45: Guardrails Integration**

- **ID de Tarea:** T-45

- **T√≠tulo:** Guardrails Integration

- **Estado:** Pendiente

- **Dependencias:** T-11

- **Prioridad:** Alta

- **Release Target:** Release 2

- **Descripci√≥n:** Implementar un sistema de "guardrails" para asegurar que las salidas de los modelos de lenguaje (LLM) se adhieran a un formato estructurado predefinido (ej. JSON, XML). Esto es crucial para la fiabilidad de los servicios que consumen estas salidas, como el Planner Service (T-05).

- **Detalles T√©cnicos:**
  - **Librer√≠a:** Guardrails AI o similar.

  - **Validaci√≥n:** Definici√≥n de esquemas de validaci√≥n (Pydantic models o similar) para las respuestas del LLM.

  - **Integraci√≥n:** Envolver las llamadas al LLM en el cliente de IA para aplicar la validaci√≥n.

- **Estrategia de Test:**
  - **Unit Tests:** Probar el validador con salidas de LLM v√°lidas e inv√°lidas. Cobertura > 90%.

  - **Integration Tests:** Integrar en el pipeline de CI un test que falle si una respuesta del LLM no cumple con el esquema.

- **Documentaci√≥n:**
  - ADR sobre la elecci√≥n de la librer√≠a de guardrails.
  - Documentar los esquemas de validaci√≥n en el c√≥digo.

- **Criterios de Aceptaci√≥n:**
  - El sistema rechaza o corrige autom√°ticamente las salidas del LLM que no se ajustan al esquema definido.
  - La cobertura de tests para la l√≥gica de validaci√≥n es ‚â• 90%.
  - El pipeline de CI falla si se detecta una regresi√≥n en la validaci√≥n de formato.

- **Definici√≥n de Hecho (DoD):**
  - C√≥digo revisado y aprobado.
  - Todos los tests (unit, integration) pasan.
  - Documentaci√≥n (ADR) completada.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 9)**

| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                                                | Complejidad Estimada | Entregable Verificable                                                                                                                            |
| :------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------ |
| R2.WP3-T45-ST1                   | Investigar y seleccionar una librer√≠a de guardrails. Definir los esquemas de validaci√≥n para las salidas clave (ej. outline del Planner). | 3                    | ADR documentando la elecci√≥n. Esquemas de validaci√≥n definidos como modelos Pydantic.                                                             |
| R2.WP3-T45-ST2                   | Integrar la librer√≠a de guardrails en el cliente de IA para validar las respuestas del LLM en tiempo de ejecuci√≥n.                        | 4                    | Test de integraci√≥n que provoca una respuesta mal formada del LLM (mock) y verifica que el sistema la maneja correctamente (rechaza o reintenta). |
| R2.WP3-T45-ST3                   | Crear tests unitarios para la l√≥gica de validaci√≥n y asegurar una cobertura > 90%.                                                        | 2                    | Reporte de cobertura de tests que muestra ‚â• 90% para los m√≥dulos de validaci√≥n.                                                                   |

---

### **Tarea T-46: DeepEval Benchmarks**

- **ID de Tarea:** T-46

- **T√≠tulo:** DeepEval Benchmarks

- **Estado:** Pendiente

- **Dependencias:** T-11

- **Prioridad:** Alta

- **Release Target:** Release 2

- **Descripci√≥n:** Implementar una suite de benchmarks automatizada utilizando un framework avanzado como DeepEval o RAGAS para evaluar de forma continua la calidad de las respuestas del sistema RAG. Se medir√°n m√©tricas como la coherencia sem√°ntica, la factualidad y la relevancia de las respuestas.

- **Detalles T√©cnicos:**
  - **Framework:** DeepEval o RAGAS.

  - **M√©tricas:** Answer Relevancy, Faithfulness, Contextual Precision.

  - **Integraci√≥n:** Job en el pipeline de CI que se ejecuta contra un dataset de evaluaci√≥n.

- **Estrategia de Test:**
  - Esta tarea es en s√≠ misma una tarea de testing de calidad.

- **Documentaci√≥n:**
  - Documentar el dataset de evaluaci√≥n y el proceso de ejecuci√≥n de los benchmarks.

- **Criterios de Aceptaci√≥n:**
  - El pipeline de CI integra la suite de benchmarks de DeepEval/RAGAS.
  - El pipeline falla si alguna de las m√©tricas de calidad clave (ej. Faithfulness) cae por debajo de un umbral predefinido (ej. 0.85).
  - Se genera un reporte HTML con los resultados de los benchmarks como artefacto de CI.

- **Definici√≥n de Hecho (DoD):**
  - C√≥digo (scripts de benchmark, dataset) revisado y aprobado.
  - El job de CI est√° configurado y es capaz de detectar una regresi√≥n de calidad.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 11)**

| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                               | Complejidad Estimada | Entregable Verificable                                                            |
| :------------------------------- | :------------------------------------------------------------------------------------------------------- | :------------------- | :-------------------------------------------------------------------------------- |
| R2.WP3-T46-ST1                   | Crear un dataset de evaluaci√≥n curado con pares de pregunta-respuesta y contextos de referencia.         | 4                    | Dataset de evaluaci√≥n en formato JSON o similar, versionado en el repositorio.    |
| R2.WP3-T46-ST2                   | Desarrollar el script de benchmark que utiliza DeepEval/RAGAS para evaluar el sistema contra el dataset. | 5                    | El script se ejecuta localmente y produce un reporte con las m√©tricas de calidad. |
| R2.WP3-T46-ST3                   | Integrar la ejecuci√≥n del script en el pipeline de CI y configurar los umbrales de fallo.                | 2                    | El pipeline de CI genera el reporte como artefacto y falla si se viola un umbral. |

---

### **Tarea T-47: Gate R4 Orchestrator Decision**

- **ID de Tarea:** T-47

- **T√≠tulo:** Gate R4 Orchestrator Decision

- **Estado:** Pendiente

- **Dependencias:** T-42 (Revisi√≥n de Riesgos de R4)

- **Prioridad:** Alta

- **Release Target:** Release 4

- **Descripci√≥n:** Tarea de proceso que formaliza la decisi√≥n de "go/no-go" sobre la adopci√≥n de un orquestador (como Kubernetes) para las releases futuras. Esta decisi√≥n se basar√° en la revisi√≥n de los KPIs de rendimiento, estabilidad y coste recopilados hasta el final de la Release 4, as√≠ como en los resultados del PoC de T-16.

- **Detalles T√©cnicos:**
  - **Proceso:** Tarea de gesti√≥n, no de desarrollo.
  - **Entregable:** Un Architecture Decision Record (ADR) que documenta la decisi√≥n y su justificaci√≥n.

- **Estrategia de Test:** N/A (Tarea de proceso).

- **Documentaci√≥n:** El entregable principal es el ADR.

- **Criterios de Aceptaci√≥n:**
  - Se ha realizado una reuni√≥n formal de revisi√≥n de KPIs con el Product Owner y el Tech Lead.
  - Se ha publicado el ADR-003 con la decisi√≥n "go/no-go" y su justificaci√≥n detallada.

- **Definici√≥n de Hecho (DoD):**
  - Minuta de la reuni√≥n de revisi√≥n completada.
  - ADR-003 publicado y aprobado.
  - Todas las subtareas verificadas como completas.

#### **Desglose en Subtareas (Complejidad Total: 3)**

_Nota: La complejidad total de 3 representa el overhead de gesti√≥n y coordinaci√≥n, y no se desglosa en las subtareas de ejecuci√≥n que tienen complejidad 0._

| ID del Elemento de Trabajo (WII) | Descripci√≥n de la Subtarea                                                                                  | Complejidad Estimada | Entregable Verificable                                                    |
| :------------------------------- | :---------------------------------------------------------------------------------------------------------- | :------------------- | :------------------------------------------------------------------------ |
| R4.WP2-T47-ST1                   | Convocar y facilitar la reuni√≥n de revisi√≥n de KPIs y resultados del PoC (T-16) con los stakeholders clave. | 0                    | Minuta de la reuni√≥n con los datos analizados y la decisi√≥n preliminar.   |
| R4.WP2-T47-ST2                   | Redactar y proponer el ADR-003 documentando la decisi√≥n final y la justificaci√≥n basada en los datos.       | 0                    | Borrador del ADR-003 enviado para revisi√≥n.                               |
| R4.WP2-T47-ST3                   | Publicar la versi√≥n final del ADR-003 una vez aprobado.                                                     | 0                    | ADR-003 fusionado en la rama principal y registrado en el √≠ndice de ADRs. |
